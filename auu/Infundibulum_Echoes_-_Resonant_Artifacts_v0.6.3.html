<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, viewport-fit=cover">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Infundibulum Echoes - Resonant Artifacts v0.6.3</title>
    <style>
        html, body { margin: 0; padding: 0; overflow: hidden; height: 100%; width: 100%; background-color: #000; color: #fff; font-family: sans-serif; cursor: none; -webkit-tap-highlight-color: transparent; touch-action: manipulation; }
        canvas { display: block; width: 100%; height: 100%; }
        #debugInfo { position: absolute; top: 5px; left: 5px; color: rgba(200,200,200,0.7); font-family: monospace; font-size: 7px; line-height: 1.2; background-color: rgba(0,0,0,0.5); padding: 3px 5px; border-radius: 3px; display: none; z-index: 10; pointer-events: none; max-width: calc(100% - 10px); white-space: normal; word-wrap: break-word; }
        #warningInfo { position: absolute; bottom: 10px; left: 10px; color: yellow; font-family: sans-serif; font-size: 12px; background-color: rgba(0,0,0,0.6); padding: 8px; border-radius: 5px; display: block; z-index: 10; pointer-events: none; }
        #loadingInfo { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); color: #eee; font-size: 14px; background-color: rgba(0,0,0,0.7); padding: 15px; border-radius: 8px; display: none; z-index: 10; text-align: center; pointer-events: none; }
        #resetButton { position: absolute; bottom: -999px; left: -999px; width: 1px; height: 1px; opacity: 0; pointer-events: none; }
        #speechStatus { position: absolute; top: 10px; right: 10px; color: rgba(180, 180, 255, 0.6); font-family: monospace; font-size: 9px; background-color: rgba(0,0,50,0.4); padding: 2px 4px; border-radius: 3px; display: none; z-index: 10; pointer-events: none; }
        /* lil-gui custom positioning */
        .lil-gui.autoPlace { top: 10px; right: 10px; z-index: 20 !important; max-height: calc(100vh - 20px); overflow-y: auto; }
    </style>
</head>
<body>
    <canvas id="renderCanvas"></canvas>
    <div id="debugInfo">Debug Info Placeholder</div>
    <div id="warningInfo">Interact to initialize. Long Press + Tap to Reset. Say "Reset Echoes" for voice command.</div>
    <div id="loadingInfo">Loading Assets...<br><span id="loadingProgress"></span></div>
    <div id="speechStatus">Speech: Idle</div>
    <button id="resetButton">Reset</button>

    <!-- External Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0/dist/tf.min.js"></script>
    <!-- Embedded hnm_core_v1.js -->
    <script type="module">
        // --- START OF hnm_core_v1.js CONTENT ---
        // hnm_core_v1.js
        // --- Logging Utility (Adapted for Resonant Artifacts context) ---
        function hnmLog(message, level = "info") {
            // In this embedded version, we'll check if the game's logMessage exists
            // otherwise, fallback to console.
            if (typeof logMessage === 'function' && typeof window.logMessage !== 'undefined' && window.logMessage === logMessage) {
                 window.logMessage(`[HNM] ${message}`, level);
            } else {
                 console[level](`[HNM] ${message}`);
            }
        }

        // --- TensorFlow.js dependent HNM Components ---

        class MemoryMLP_TFJS {
            constructor(inputDim, depth, expansionOrTargetDim, namePrefix = '', activation = 'elu') {
                this.inputDim = inputDim;
                this.depth = depth;
                this.namePrefix = namePrefix;
                this.model = null;
                this.isDisposed = false;

                if (depth < 1) { this.isIdentity = true; return; }
                this.isIdentity = false;

                const layers = [];
                let currentLayerInputShape = [this.inputDim];

                for (let i = 0; i < depth; i++) {
                    const isLast = i === (depth - 1);
                    let currentLayerOutputUnits;

                    if (depth === 1) { currentLayerOutputUnits = expansionOrTargetDim; }
                    else { currentLayerOutputUnits = isLast ? this.inputDim : Math.floor(this.inputDim * expansionOrTargetDim); }

                    const denseLayerConfig = {
                        units: currentLayerOutputUnits, kernelInitializer: 'glorotUniform',
                        biasInitializer: 'zeros', name: `${namePrefix}_mlp_dense_${i}`
                    };
                    if (i === 0) { denseLayerConfig.inputShape = currentLayerInputShape; }
                    layers.push(tf.layers.dense(denseLayerConfig));
                    currentLayerInputShape = [currentLayerOutputUnits];

                    if (!isLast) { layers.push(tf.layers.activation({activation: activation, name: `${namePrefix}_mlp_act_${i}`})); }
                }
                this.model = tf.sequential({ name: `${namePrefix}_mlp_sequential`, layers });
            }

            call(inputs) {
                if (this.isDisposed) throw new Error(`${this.namePrefix} MLP model is disposed.`);
                if (this.isIdentity) return tf.keep(inputs.clone());
                if (!this.model) throw new Error (`MemoryMLP_TFJS (${this.namePrefix}): Model not initialized properly.`);
                return this.model.apply(inputs);
            }

            getWeights() {
                if (this.isDisposed || this.isIdentity || !this.model) return [];
                return this.model.getWeights().map(w => tf.keep(w.clone()));
            }

            setWeights(weights) {
                if (this.isDisposed || this.isIdentity || !this.model || !weights || weights.length === 0) return;
                this.model.setWeights(weights);
            }

            getTrainableVariables() {
                if (this.isDisposed || this.isIdentity || !this.model) return [];
                return this.model.trainableWeights.map(tw => tw.val);
            }

            dispose() {
                if (this.isDisposed) return;
                if (this.model && typeof this.model.dispose === 'function') { this.model.dispose(); }
                this.model = null; this.isDisposed = true;
            }
        }

        function createNeuralMemState(seq_index = 0, layerWeights = {}, optim_state = {}) {
            return { seq_index, layerWeights, optim_state };
        }

        function memStateDetach(state) {
            if (!state) return null;
            const detachedLayerWeights = {};
            for (const key in state.layerWeights) {
                if (Array.isArray(state.layerWeights[key])) {
                    detachedLayerWeights[key] = state.layerWeights[key].map(t => {
                        if (t && !t.isDisposed) return tf.keep(t.clone());
                        hnmLog(`Warning: memStateDetach found disposed or null tensor for weight key ${key}. Returning null for this tensor.`, "warn");
                        return null;
                    }).filter(t => t !== null);
                } else {
                    hnmLog(`Warning: memStateDetach encountered non-array weights for key ${key}`, "warn");
                    detachedLayerWeights[key] = [];
                }
            }
            const detachedOptimState = JSON.parse(JSON.stringify(state.optim_state || {}));
            return createNeuralMemState(state.seq_index, detachedLayerWeights, detachedOptimState);
        }

        function disposeMemStateWeights(state) {
            if (state && state.layerWeights) {
                for (const key in state.layerWeights) {
                    if (Array.isArray(state.layerWeights[key])) {
                        state.layerWeights[key].forEach(t => { if (t && !t.isDisposed) t.dispose(); });
                    }
                }
                state.layerWeights = {};
            }
        }

        function disposeHnsResultsTensors(hnsResults) {
            if (!hnsResults) return;
            const tensorDictionaries = [
                hnsResults.anomalies,
                hnsResults.weightChanges,
                hnsResults.buNorms,
                hnsResults.tdNorms,
                hnsResults.extNorms
            ];
            tensorDictionaries.forEach(dict => {
                if (dict) {
                    Object.values(dict).forEach(tensor => {
                        if (tensor && !tensor.isDisposed && typeof tensor.dispose === 'function') {
                            tensor.dispose();
                        }
                    });
                }
            });
        }


        class NMM_TD_V5_TFJS {
            constructor(config) {
                this.levelName = config.name; this.dim = config.dim;
                this.buInputDims = { ...(config.bu_input_dims || {}) };
                this.tdInputDims = { ...(config.td_input_dims || {}) };

                this.nmmParams = {
                    mem_model_depth: 2,
                    mem_model_expansion: 2.0,
                    learning_rate: 0.000, // Effectively no training for this integration by default
                    weight_decay: 0.000,  // No decay
                    beta1: 0.9,
                    beta2: 0.999,
                    max_grad_norm: 1.0,
                    external_signal_dim: config.nmm_params?.external_signal_dim || 0,
                    external_signal_role: config.nmm_params?.external_signal_role || 'none',
                    verbose: config.nmm_params?.verbose || false,
                    ...(config.nmm_params || {}) // Allow overrides
                };
                if (this.nmmParams.learning_rate === 0) {
                     if(this.nmmParams.verbose) hnmLog(`NMM_TD_V5_TFJS (${this.levelName}): LR is 0, training ops will be skipped.`);
                }


                this.memoryModel = new MemoryMLP_TFJS(this.dim, this.nmmParams.mem_model_depth, this.nmmParams.mem_model_expansion, `${this.levelName}_mem_mlp`);
                this.toValueTarget = new MemoryMLP_TFJS(this.dim, 1, this.dim, `${this.levelName}_val_proj`);

                this.buProjections = {};
                for (const name in this.buInputDims) { this.buProjections[name] = new MemoryMLP_TFJS(this.buInputDims[name], 1, this.dim, `${this.levelName}_bu_proj_${name}`); }
                this.tdProjections = {};
                for (const name in this.tdInputDims) { this.tdProjections[name] = new MemoryMLP_TFJS(this.tdInputDims[name], 1, this.dim, `${this.levelName}_td_proj_${name}`); }

                this.externalSignalProjection = null;
                if (this.nmmParams.external_signal_dim > 0 && this.nmmParams.external_signal_role !== 'none') {
                    this.externalSignalProjection = new MemoryMLP_TFJS(this.nmmParams.external_signal_dim, 1, this.dim, `${this.levelName}_ext_proj`);
                }

                this.lossFn = (labels, predictions) => tf.losses.meanSquaredError(labels, predictions);
                if (this.nmmParams.learning_rate > 0) {
                    this.optimizer = tf.train.adam(this.nmmParams.learning_rate, this.nmmParams.beta1, this.nmmParams.beta2, 1e-7);
                } else {
                    this.optimizer = null; // No optimizer if not learning
                }
                if(this.nmmParams.verbose) hnmLog(`NMM_TD_V5_TFJS (${this.levelName}): Dim=${this.dim}, ExtDim=${this.nmmParams.external_signal_dim}, Role=${this.nmmParams.external_signal_role}, LR=${this.nmmParams.learning_rate.toExponential(2)}`);
                this.isDisposed = false;
            }

            _getLayerWeights() {
                if (this.isDisposed) throw new Error(`${this.levelName} NMM is disposed.`);
                const weights = { memoryModel: this.memoryModel.getWeights(), toValueTarget: this.toValueTarget.getWeights() };
                for (const name in this.buProjections) { weights[`buProj_${name}`] = this.buProjections[name].getWeights(); }
                for (const name in this.tdProjections) { weights[`tdProj_${name}`] = this.tdProjections[name].getWeights(); }
                if (this.externalSignalProjection) { weights.externalSignalProjection = this.externalSignalProjection.getWeights(); }
                return weights;
            }

            _applyLayerWeights(layerWeights) {
                if (this.isDisposed) throw new Error(`${this.levelName} NMM is disposed.`);
                if (!layerWeights) return;

                const tempClonedWeights = {};
                for (const key in layerWeights) {
                    if (Array.isArray(layerWeights[key])) {
                        tempClonedWeights[key] = layerWeights[key].map(t => t && !t.isDisposed ? t.clone() : null).filter(t => t);
                    }
                }

                this.memoryModel.setWeights(tempClonedWeights.memoryModel || []);
                this.toValueTarget.setWeights(tempClonedWeights.toValueTarget || []);
                for (const name in this.buProjections) { this.buProjections[name].setWeights(tempClonedWeights[`buProj_${name}`] || []); }
                for (const name in this.tdProjections) { this.tdProjections[name].setWeights(tempClonedWeights[`tdProj_${name}`] || []); }
                if (this.externalSignalProjection && tempClonedWeights.externalSignalProjection) { this.externalSignalProjection.setWeights(tempClonedWeights.externalSignalProjection || []); }

                for (const key in tempClonedWeights) {
                    if (Array.isArray(tempClonedWeights[key])) {
                        tempClonedWeights[key].forEach(t => { if (t && !t.isDisposed) t.dispose(); });
                    }
                }
            }

            getInitialState() {
                if (this.isDisposed) throw new Error(`${this.levelName} NMM is disposed.`);
                return createNeuralMemState(0, this._getLayerWeights(), { lr: this.nmmParams.learning_rate, wd: this.nmmParams.weight_decay });
            }

           _calculateWeightChange(oldWeightsMap, newWeightsMap) {
                return tf.tidy(`${this.levelName}_WeightChange`,() => {
                    if (this.nmmParams.learning_rate === 0) return tf.keep(tf.tensor(0.0)); // No change if not learning

                    let totalDiffSqSum = tf.tensor(0.0);
                     for (const key in newWeightsMap) {
                         const oldWArray = oldWeightsMap[key]; const newWArray = newWeightsMap[key];
                         if (oldWArray && newWArray && oldWArray.length === newWArray.length) {
                             for (let i = 0; i < newWArray.length; i++) {
                                 const oldW = oldWArray[i]; const newW = newWArray[i];
                                 if (oldW && newW && !oldW.isDisposed && !newW.isDisposed && oldW.shape.toString() === newW.shape.toString()) {
                                     const diff = newW.sub(oldW);
                                     totalDiffSqSum = totalDiffSqSum.add(diff.square().sum());
                                     diff.dispose();
                                 } else { if(this.nmmParams.verbose) hnmLog(`Warning: Tensor mismatch or disposal during weight change calc for ${key}[${i}]`, "warn"); }
                             }
                         }
                     }
                    return tf.keep(totalDiffSqSum.sqrt());
                });
            }


            forwardStep(buInputs, tdSignals, currentState, externalSignal = null, detachNextState = true) {
                if (this.isDisposed) throw new Error(`${this.levelName} NMM is disposed.`);

                const oldWeightsForChangeCalc = (this.nmmParams.learning_rate > 0) ? this._getLayerWeights() : null;
                this._applyLayerWeights(currentState.layerWeights);

                const resultsTidy = tf.tidy(`${this.levelName}_NMM_ForwardStep`, () => {
                    const preparedInputs = tf.tidy(`${this.levelName}_InputPrep`, () => {
                        const projectedBuSignals = [];
                        for (const name in buInputs) {
                            if (this.buProjections[name] && buInputs[name] && !buInputs[name].isDisposed && buInputs[name].shape) {
                                projectedBuSignals.push(this.buProjections[name].call(buInputs[name].reshape([-1, this.buInputDims[name]])));
                            } else {
                                if(this.nmmParams.verbose) hnmLog(`Warning: Skipping BU input for ${name} in ${this.levelName}. Using zeros.`, "warn");
                                projectedBuSignals.push(tf.zeros([1, this.dim]));
                            }
                        }
                        const combBu = projectedBuSignals.length > 0 ? tf.addN(projectedBuSignals) : tf.zeros([1, this.dim]);
                        projectedBuSignals.forEach(t => {if (t && !t.isDisposed) t.dispose(); });
                        const cBuNorm = tf.norm(combBu);

                        const projectedTdSignals = [];
                        for (const name in tdSignals) {
                            if (this.tdProjections[name] && tdSignals[name] && !tdSignals[name].isDisposed && tdSignals[name].shape) {
                                projectedTdSignals.push(this.tdProjections[name].call(tdSignals[name].reshape([-1, this.tdInputDims[name]])));
                            } else {
                               if(this.nmmParams.verbose) hnmLog(`Warning: Skipping TD input for ${name} in ${this.levelName}. Using zeros.`, "warn");
                               projectedTdSignals.push(tf.zeros([1, this.dim]));
                            }
                        }
                        const combTd = projectedTdSignals.length > 0 ? tf.addN(projectedTdSignals) : tf.zeros([1, this.dim]);
                        projectedTdSignals.forEach(t => {if (t && !t.isDisposed) t.dispose(); });
                        const cTdNorm = tf.norm(combTd);

                        let projExtSig = null;
                        let cExtNorm = tf.tensor(0.0);
                        if (this.nmmParams.external_signal_role !== 'none' && this.externalSignalProjection) {
                            if (externalSignal && !externalSignal.isDisposed && externalSignal.shape && externalSignal.shape.length === 3 && externalSignal.shape[externalSignal.shape.length -1] === this.nmmParams.external_signal_dim) {
                               projExtSig = this.externalSignalProjection.call(externalSignal.reshape([-1, this.nmmParams.external_signal_dim]));
                            } else {
                                if(this.nmmParams.verbose && externalSignal) hnmLog(`Warning: External signal for ${this.levelName} invalid. Using zeros. Expected dim ${this.nmmParams.external_signal_dim}, got shape ${externalSignal?.shape}`, "warn");
                                else if (this.nmmParams.verbose && !externalSignal && this.nmmParams.external_signal_dim > 0) hnmLog(`Warning: External signal for ${this.levelName} missing. Using zeros. Expected dim ${this.nmmParams.external_signal_dim}`, "warn");
                                projExtSig = tf.zeros([1, this.dim]);
                            }
                            cExtNorm.dispose();
                            cExtNorm = tf.norm(projExtSig);
                        }

                        let keyBaseForPredictionTarget = combBu.clone();
                        if (this.nmmParams.external_signal_role === 'add_to_bu' && projExtSig) {
                            keyBaseForPredictionTarget = keyBaseForPredictionTarget.add(projExtSig);
                        }

                        let mInput = combBu.add(combTd);
                        if (this.nmmParams.external_signal_role === 'add_to_bu' && projExtSig) {
                            mInput = mInput.add(projExtSig);
                        } else if (this.nmmParams.external_signal_role === 'add_to_td' && projExtSig) {
                            mInput = mInput.add(projExtSig);
                        }

                        let fValTarget = this.toValueTarget.call(keyBaseForPredictionTarget);
                        if (this.nmmParams.external_signal_role === 'add_to_target' && projExtSig) {
                            fValTarget = fValTarget.add(projExtSig);
                        }
                        if (projExtSig && projExtSig !== externalSignal && !projExtSig.isDisposed && projExtSig.rank > 0) projExtSig.dispose();

                        return { memInput: mInput, finalValTarget: fValTarget, currentBuNorm: cBuNorm, currentTdNorm: cTdNorm, currentExtNorm: cExtNorm };
                    });

                    const keptBuNorm = tf.keep(preparedInputs.currentBuNorm);
                    const keptTdNorm = tf.keep(preparedInputs.currentTdNorm);
                    const keptExtNorm = tf.keep(preparedInputs.currentExtNorm);

                    const predictionBeforeTrain = this.memoryModel.call(preparedInputs.memInput);
                    const keptPredictionForOutput = tf.keep(predictionBeforeTrain.clone().reshape([1, 1, this.dim]));

                    let currentLossTensor = tf.tensor(0.0);

                    if (this.optimizer && this.nmmParams.learning_rate > 0) {
                        const trainableVarsForOptimizer = [];
                        this.memoryModel.getTrainableVariables().forEach(v => trainableVarsForOptimizer.push(v));
                        if (this.externalSignalProjection && this.nmmParams.external_signal_role !== 'none' && this.nmmParams.external_signal_dim > 0) {
                             this.externalSignalProjection.getTrainableVariables().forEach(v => trainableVarsForOptimizer.push(v));
                        }

                        if (trainableVarsForOptimizer.length > 0) {
                            const calculateLossFn = () => {
                                const currentPred = this.memoryModel.call(preparedInputs.memInput);
                                let mseLoss = this.lossFn(preparedInputs.finalValTarget, currentPred);
                                if (this.nmmParams.weight_decay > 0) {
                                    let l2Loss = tf.tensor(0.0);
                                    trainableVarsForOptimizer.forEach(v => { if (v.name.includes('kernel')) { l2Loss = l2Loss.add(v.square().sum()); } });
                                    mseLoss = mseLoss.add(l2Loss.mul(this.nmmParams.weight_decay / 2));
                                    l2Loss.dispose();
                                }
                                return mseLoss;
                            };

                            if (this.nmmParams.max_grad_norm && this.nmmParams.max_grad_norm > 0) {
                                const {value, grads} = this.optimizer.computeGradients(calculateLossFn, trainableVarsForOptimizer);
                                currentLossTensor.dispose(); currentLossTensor = value ? tf.keep(value) : tf.keep(tf.tensor(0.0));
                                 if (grads) {
                                    const gradArray = trainableVarsForOptimizer.map(v => grads[v.name]).filter(g => g && !g.isDisposed);
                                    let finalGradsForApply = {};
                                    if (gradArray.length > 0) {
                                        const globalNorm = tf.tidy('globalNormCalc', () => { let totalNormSq = tf.scalar(0.0); for (const grad of gradArray) { totalNormSq = totalNormSq.add(tf.norm(grad).square()); } return totalNormSq.sqrt(); });
                                        const globalNormVal = globalNorm.dataSync()[0]; globalNorm.dispose();
                                        let clipRatioScalar = null; if (globalNormVal > this.nmmParams.max_grad_norm) { clipRatioScalar = tf.scalar(this.nmmParams.max_grad_norm / (globalNormVal + 1e-6)); }
                                        trainableVarsForOptimizer.forEach(v => { if (grads[v.name] && !grads[v.name].isDisposed) { finalGradsForApply[v.name] = clipRatioScalar ? grads[v.name].mul(clipRatioScalar) : grads[v.name].clone(); } });
                                        if (clipRatioScalar) clipRatioScalar.dispose();
                                    }
                                    this.optimizer.applyGradients(finalGradsForApply);
                                    trainableVarsForOptimizer.forEach(v => { if (grads[v.name] && !grads[v.name].isDisposed) grads[v.name].dispose(); });
                                    Object.values(finalGradsForApply).forEach(g => {if (g && !g.isDisposed) g.dispose(); });
                                 } else { if(this.nmmParams.verbose) hnmLog(`Warning: Grads object from computeGradients is null/undefined for NMM ${this.levelName}.`, "warn");}
                            } else {
                                const lossTensorFromOptimizer = this.optimizer.minimize(calculateLossFn, true, trainableVarsForOptimizer);
                                currentLossTensor.dispose(); currentLossTensor = lossTensorFromOptimizer ? tf.keep(lossTensorFromOptimizer) : tf.keep(tf.tensor(0.0));
                            }
                        } else { if(this.nmmParams.verbose) hnmLog(`Warning: No trainable variables for NMM ${this.levelName}. Training skipped.`, "warn"); }
                    } else {
                        currentLossTensor.dispose();
                        currentLossTensor = tf.keep(this.lossFn(predictionBeforeTrain, preparedInputs.finalValTarget));
                    }
                    if (preparedInputs.memInput && !preparedInputs.memInput.isDisposed) preparedInputs.memInput.dispose();
                    if (preparedInputs.finalValTarget && !preparedInputs.finalValTarget.isDisposed) preparedInputs.finalValTarget.dispose();

                    return { prediction: keptPredictionForOutput, loss: currentLossTensor, buNorm: keptBuNorm, tdNorm: keptTdNorm, extNorm: keptExtNorm };
                });

                const retrievedValForOutput = resultsTidy.prediction;
                const lossVal = resultsTidy.loss;
                const buNormVal = resultsTidy.buNorm;
                const tdNormVal = resultsTidy.tdNorm;
                const extNormVal = resultsTidy.extNorm;

                let weightChangeVal;
                let newModelWeightsAfterTraining;
                if (this.nmmParams.learning_rate > 0 && oldWeightsForChangeCalc) {
                    newModelWeightsAfterTraining = this._getLayerWeights();
                    weightChangeVal = this._calculateWeightChange(oldWeightsForChangeCalc, newModelWeightsAfterTraining);
                    Object.values(oldWeightsForChangeCalc).forEach(arr => arr.forEach(t => { if (t && !t.isDisposed) t.dispose(); }));
                } else {
                    weightChangeVal = tf.keep(tf.tensor(0.0));
                    newModelWeightsAfterTraining = currentState.layerWeights;
                }


                const nextStateInterim = createNeuralMemState(currentState.seq_index + 1, newModelWeightsAfterTraining, currentState.optim_state);
                const nextStateFinal = detachNextState ? memStateDetach(nextStateInterim) : nextStateInterim;
                if (detachNextState && this.nmmParams.learning_rate > 0 && newModelWeightsAfterTraining !== currentState.layerWeights) {
                     disposeMemStateWeights(nextStateInterim);
                } else if (detachNextState && this.nmmParams.learning_rate === 0) {
                    // No disposal needed here if not training, as memStateDetach clones.
                }


                return { retrievedVal: retrievedValForOutput, nextState: nextStateFinal, anomalyScore: lossVal, weightChange: weightChangeVal, buNorm: buNormVal, tdNorm: tdNormVal, extNorm: extNormVal };
            }

            dispose() {
                if (this.isDisposed) return;
                this.memoryModel.dispose(); this.toValueTarget.dispose();
                Object.values(this.buProjections).forEach(p => p.dispose()); Object.values(this.tdProjections).forEach(p => p.dispose());
                if(this.externalSignalProjection) this.externalSignalProjection.dispose();
                this.isDisposed = true; hnmLog(`NMM ${this.levelName} disposed.`);
            }
        }


        class HierarchicalSystemV5_TFJS {
            constructor(levelConfigsHLC, globalSimConfig) {
                this.levelConfigsOriginal = JSON.parse(JSON.stringify(levelConfigsHLC));
                this.globalConfig = globalSimConfig;
                this.numLevels = 0; this.levels = [];
                this.levelNameToIndex = {}; this.dims = {}; this.isDisposed = false;
                this.level_expected_external_details = [];

                this._initializeLevels();
            }

            _initializeLevels() {
                hnmLog(`HS_V5_TFJS: Initializing ${this.levelConfigsOriginal.length} levels.`);
                this.levelConfigsOriginal.forEach((cfg, i) => {
                    if (!cfg.name || !cfg.dim) throw new Error(`Level ${i} config missing name or dim.`);
                    this.levelNameToIndex[cfg.name] = i; this.dims[cfg.name] = cfg.dim;
                });

                this.levelConfigsOriginal.forEach((hlc_level_cfg, i) => {
                    const nmmConstructorConfig = {
                        name: hlc_level_cfg.name,
                        dim: hlc_level_cfg.dim,
                        bu_input_dims: {},
                        td_input_dims: {},
                        nmm_params: {
                            verbose: this.globalConfig.HNM_VERBOSE || false,
                            learning_rate: 0.000, // Defaulting to no learning for this integration
                            weight_decay: 0.000,
                            beta1: 0.9, beta2: 0.999, max_grad_norm: 1.0,
                            external_signal_dim: 0, external_signal_role: 'none',
                            mem_model_depth: 2, mem_model_expansion: 2.0,
                            ...(hlc_level_cfg.nmm_params || {})
                        }
                    };

                    if (!hlc_level_cfg.bu_source_level_names || hlc_level_cfg.bu_source_level_names.length === 0) {
                        if (!hlc_level_cfg.raw_sensory_input_dim || hlc_level_cfg.raw_sensory_input_dim <= 0) {
                            throw new Error(`Lvl '${hlc_level_cfg.name}' is a sensory level but lacks a valid 'raw_sensory_input_dim'.`);
                        }
                        nmmConstructorConfig.bu_input_dims[hlc_level_cfg.name] = hlc_level_cfg.raw_sensory_input_dim;
                    } else {
                        hlc_level_cfg.bu_source_level_names.forEach(srcName => {
                            if (!this.dims[srcName]) throw new Error(`Unknown BU source '${srcName}' for level '${hlc_level_cfg.name}'.`);
                            nmmConstructorConfig.bu_input_dims[srcName] = this.dims[srcName];
                        });
                    }
                    if (hlc_level_cfg.td_source_level_names) {
                         hlc_level_cfg.td_source_level_names.forEach(srcName => {
                            if (!this.dims[srcName]) throw new Error(`Unknown TD source '${srcName}' for level '${hlc_level_cfg.name}'.`);
                            nmmConstructorConfig.td_input_dims[srcName] = this.dims[srcName];
                        });
                    }

                    let expectedNmmExtSourceName = null;
                    let nmmExtSignalDimForNMM = 0;
                    // NMM's external_signal_role is taken from its nmm_params which can be overridden by hlc_level_cfg.nmm_params
                    let nmmExtSignalRoleForNMM = nmmConstructorConfig.nmm_params.external_signal_role;

                    // external_input_config on hlc_level_cfg should be a single object for this NMM_TD_V5_TFJS
                    const specificExtConfig = hlc_level_cfg.external_input_config;
                    if (specificExtConfig && typeof specificExtConfig === 'object' && !Array.isArray(specificExtConfig) &&
                        specificExtConfig.source_signal_name && specificExtConfig.dim > 0) {

                        expectedNmmExtSourceName = specificExtConfig.source_signal_name;
                        nmmExtSignalDimForNMM = specificExtConfig.dim;

                        // If role is defined in external_input_config, it was intended to be part of nmm_params.
                        // For HNM V5, role is part of NMM's own nmm_params.
                        // If external_input_config.role exists, it would usually be copied into nmm_params.external_signal_role.
                        // Here, we assume nmmConstructorConfig.nmm_params.external_signal_role is already correctly set by `...(hlc_level_cfg.nmm_params || {})`
                        // If dim is present but role is 'none' in nmm_params, default to 'add_to_bu'
                        if (nmmExtSignalDimForNMM > 0 && nmmExtSignalRoleForNMM === 'none') {
                            nmmExtSignalRoleForNMM = 'add_to_bu';
                        }
                    } else if (specificExtConfig && nmmConstructorConfig.nmm_params.verbose) {
                        hnmLog(`Warning for ${hlc_level_cfg.name}: external_input_config is present but invalid or incomplete. ${JSON.stringify(specificExtConfig)}`, "warn");
                    }

                    nmmConstructorConfig.nmm_params.external_signal_dim = nmmExtSignalDimForNMM;
                    nmmConstructorConfig.nmm_params.external_signal_role = nmmExtSignalRoleForNMM;
                    this.level_expected_external_details[i] = { name: expectedNmmExtSourceName, dim: nmmExtSignalDimForNMM };

                    this.levels.push(new NMM_TD_V5_TFJS(nmmConstructorConfig));
                });
                this.numLevels = this.levels.length;
                hnmLog(`HS_V5_TFJS: Initialization complete. ${this.levels.length} levels created.`);
            }

            getInitialStates() {
                if (this.isDisposed) throw new Error(`HNS is disposed.`);
                return this.levels.map(level => level.getInitialState());
            }

            step(currentBotLevelStates, currentBotLastStepOutputs, sensoryInputs, externalInputsAllSources = {}, detachNextStatesMemory = true) {
                if (this.isDisposed) throw new Error(`HNS is disposed.`);

                const nextBotLevelStatesList = new Array(this.numLevels).fill(null);
                const newlyRetrievedValuesForAllLevelsDict = {};
                const stepAnomalies = {}; const stepWeightChanges = {};
                const stepBuNorms = {}; const stepTdNorms = {}; const stepExternalNorms = {};
                const currentStepIntermediateOutputs = {};

                for (let i = 0; i < this.numLevels; i++) {
                    const lvlMgr = this.levels[i]; const cfg = this.levelConfigsOriginal[i];
                    const lvlName = cfg.name; const buSrcNames = cfg.bu_source_level_names || []; const tdSrcNames = cfg.td_source_level_names || [];
                    const currentLevelSpecificState = currentBotLevelStates[i];
                    const lvlBuIn = {}; const lvlTdIn = {};

                    if (buSrcNames.length === 0) { // This is a root sensory level
                        const rawSensoryDim = cfg.raw_sensory_input_dim; // The dim this level expects for its raw sensory input
                        const sensoryInputTensor = sensoryInputs[lvlName]; // Get the tensor for this specific level

                        if (sensoryInputTensor && !sensoryInputTensor.isDisposed &&
                            sensoryInputTensor.shape && sensoryInputTensor.shape.length === 3 && // Expect [1,1,dim]
                            sensoryInputTensor.shape[0] === 1 && sensoryInputTensor.shape[1] === 1 &&
                            sensoryInputTensor.shape[2] === rawSensoryDim) {
                            lvlBuIn[lvlName] = sensoryInputTensor; // Keyed by its own name for sensory input
                        } else {
                            if(lvlMgr.nmmParams.verbose) hnmLog(`Warning: Sensory input for ${lvlName} is invalid or missing. Using zeros. Expected shape [1,1,${rawSensoryDim}], got ${sensoryInputTensor?.shape}`, "warn");
                            lvlBuIn[lvlName] = tf.keep(tf.zeros([1, 1, rawSensoryDim]));
                        }
                    } else { // This level gets BU input from other levels' current step outputs
                        buSrcNames.forEach(srcName => {
                            const buSourceOutput = currentStepIntermediateOutputs[srcName]; // Output from a previous level *in this same step*
                            if (buSourceOutput && !buSourceOutput.isDisposed) { lvlBuIn[srcName] = buSourceOutput; }
                            else {
                                hnmLog(`Warning: Missing BU source output from '${srcName}' for level '${lvlName}' in current step. Using zeros.`, "warn");
                                lvlBuIn[srcName] = tf.keep(tf.zeros([1, 1, this.dims[srcName]]));
                            }
                        });
                    }

                    // TD inputs come from *last* step's outputs of higher levels
                    tdSrcNames.forEach(srcName => {
                        const tdSourceOutput = currentBotLastStepOutputs[srcName]?.retrievedVal; // From HNM's previous full pass
                        if (tdSourceOutput && !tdSourceOutput.isDisposed) { lvlTdIn[srcName] = tdSourceOutput; }
                        else { // If TD signal is missing, provide zeros
                            lvlTdIn[srcName] = tf.keep(tf.zeros([1, 1, this.dims[srcName]]));
                        }
                    });

                    // External input for this specific NMM
                    let lvlExtInForNMMStep = null;
                    const expectedExternal = this.level_expected_external_details[i]; // {name, dim} this NMM expects
                    if (expectedExternal && expectedExternal.name && expectedExternal.dim > 0) {
                        const providedSignal = externalInputsAllSources[expectedExternal.name];
                        if (providedSignal && !providedSignal.isDisposed && providedSignal.shape &&
                            providedSignal.shape.length === 3 && providedSignal.shape[0] === 1 &&
                            providedSignal.shape[1] === 1 && providedSignal.shape[2] === expectedExternal.dim) {
                            lvlExtInForNMMStep = providedSignal;
                        } else {
                            if(lvlMgr.nmmParams.verbose) hnmLog(`Warning for ${lvlName}: External signal '${expectedExternal.name}' invalid or missing from externalInputsAllSources. Using zeros. Expected dim ${expectedExternal.dim}, got ${providedSignal?.shape}`, "warn");
                            lvlExtInForNMMStep = tf.keep(tf.zeros([1,1,expectedExternal.dim]));
                        }
                    }


                    const nmmOutputs = lvlMgr.forwardStep(lvlBuIn, lvlTdIn, currentLevelSpecificState, lvlExtInForNMMStep, detachNextStatesMemory);

                    nextBotLevelStatesList[i] = nmmOutputs.nextState;
                    currentStepIntermediateOutputs[lvlName] = tf.keep(nmmOutputs.retrievedVal.clone()); // This level's output for current step
                    newlyRetrievedValuesForAllLevelsDict[lvlName] = nmmOutputs.retrievedVal; // For the final HNS output dict

                    stepAnomalies[lvlName] = nmmOutputs.anomalyScore;
                    stepWeightChanges[lvlName] = nmmOutputs.weightChange;
                    stepBuNorms[lvlName] = nmmOutputs.buNorm;
                    stepTdNorms[lvlName] = nmmOutputs.tdNorm;
                    stepExternalNorms[lvlName] = nmmOutputs.extNorm;

                    // Dispose temporary zero tensors if they were created and not the original inputs
                    Object.entries(lvlBuIn).forEach(([key, t]) => { if (t !== sensoryInputs[lvlName] && t !== currentStepIntermediateOutputs[key] && t.rank === 3 && t.shape[0] === 1 && !t.isDisposed && t.dataSync().every(v => v ===0) ) t.dispose(); });
                    Object.entries(lvlTdIn).forEach(([key, t]) => { if (t !== currentBotLastStepOutputs[key]?.retrievedVal && t.rank === 3 && t.shape[0] === 1 && !t.isDisposed && t.dataSync().every(v => v ===0) ) t.dispose(); });
                    if (lvlExtInForNMMStep && lvlExtInForNMMStep !== externalInputsAllSources[expectedExternal?.name] && lvlExtInForNMMStep.rank === 3 && lvlExtInForNMMStep.shape[0] === 1 && !lvlExtInForNMMStep.isDisposed && lvlExtInForNMMStep.dataSync().every(v => v ===0) ) lvlExtInForNMMStep.dispose();
                }

                // Dispose intermediate outputs from this step that were kept for BU flow
                Object.values(currentStepIntermediateOutputs).forEach(t => { if (t && !t.isDisposed) t.dispose(); });

                return { newlyRetrievedValues: newlyRetrievedValuesForAllLevelsDict, nextBotStates: nextBotLevelStatesList, anomalies: stepAnomalies, weightChanges: stepWeightChanges, buNorms: stepBuNorms, tdNorms: stepTdNorms, extNorms: stepExternalNorms };
            }

            dispose() {
                if (this.isDisposed) return;
                this.levels.forEach(l => {if (l && typeof l.dispose === 'function') l.dispose();});
                this.levels = []; this.isDisposed = true; hnmLog("HNS Disposed.");
            }
        }

        window.MemoryMLP_TFJS = MemoryMLP_TFJS;
        window.NMM_TD_V5_TFJS = NMM_TD_V5_TFJS;
        window.HierarchicalSystemV5_TFJS = HierarchicalSystemV5_TFJS;
        window.createNeuralMemState = createNeuralMemState;
        window.memStateDetach = memStateDetach;
        window.disposeMemStateWeights = disposeMemStateWeights;
        window.disposeHnsResultsTensors = disposeHnsResultsTensors;
        window.hnmLog = hnmLog; // Make hnmLog available on window if other parts of the game logic expect it

        console.log("[HNM Core] Version 1.0 (Embedded) Loaded. Classes attached to window object.");
        // --- END OF hnm_core_v1.js CONTENT ---
    </script>

    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.163.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.163.0/examples/jsm/",
                "@xenova/transformers": "https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1",
                "lil-gui": "https://unpkg.com/lil-gui@0.19.1/dist/lil-gui.esm.js"
            }
        }
    </script>

    <!-- Main Game Logic -->
    <script type="module">

        import * as THREE from 'three';
        import GUI from 'lil-gui';

        // --- Constants & Configuration ---
        const VERSION = "0.6.3-PsySynthRefactor-GenreRuleFix-MoreParams"; 
        const USE_DEBUG = true;
        const TARGET_FPS = 55;
        const STATE_VECTOR_SIZE = 64; // HNM output vector size
        const INPUT_VECTOR_SIZE = 64; 
        const EMBEDDING_DIM = 384;
        const MAX_ARTIFACTS = 16;
        const MAX_ACTIVE_ARTIFACTS_LOGIC = 4;
        let MAX_ARTIFACTS_SHADER = 1; // Will be detected
        const ARTIFACT_SIMILARITY_THRESHOLD = 0.46;
        const ARTIFACT_CREATION_INTERVAL_MS = 9000;
        const ARTIFACT_CREATION_ACTIVITY_THRESHOLD_MIN = 0.28;
        const ARTIFACT_CREATION_ACTIVITY_THRESHOLD_MAX = 0.85;
        const EMBEDDING_MODEL_NAME = 'Xenova/all-MiniLM-L6-v2';
        const MIC_FFT_SIZE = 256;
        const ACCEL_FFT_SIZE = 64;
        const LOCAL_STORAGE_KEY = `infundibulumEchoesState_v${VERSION}`;
        const LOCAL_STORAGE_MENU_KEY = `infundibulumEchoesMenuSettings_v${VERSION}`;
        const SPEECH_COMMANDS = { CREATE: ["create artifact", "make echo", "capture this", "remember this"], FORGET_OLDEST: ["forget oldest", "remove last echo", "clear history", "forget last"], RESET: ["reset echoes", "start over", "clear all", "forget everything"], };
        const SYNC_THRESHOLD = 0.3;
        const SYNC_DECAY = 0.98;
        const ACCEL_ANALYSIS_INTERVAL_S = ACCEL_FFT_SIZE / (TARGET_FPS * 0.9);
        const LONG_PRESS_DURATION_MS = 2000;
        const RESET_SECOND_TAP_WINDOW_MS = 400;
        const FULLSCREEN_REQUESTED_KEY = `infundibulumEchoesFullscreenReq_v${VERSION}`;
        const HNM_VERBOSE = false;
        const HNM_ARTIFACT_EXTERNAL_SIGNAL_DIM = STATE_VECTOR_SIZE;
        const HNM_GENRE_RULE_EXTERNAL_SIGNAL_DIM = STATE_VECTOR_SIZE;

        const HNM_HIERARCHY_LEVEL_CONFIGS = [ 
            { name: "L0_IntentProcessing", dim: 96, raw_sensory_input_dim: STATE_VECTOR_SIZE, bu_source_level_names: [], td_source_level_names: ["L1_ContextualResonance"], external_input_config: { source_signal_name: "ArtifactSignalSource", dim: HNM_ARTIFACT_EXTERNAL_SIGNAL_DIM }, nmm_params: { mem_model_depth: 2, mem_model_expansion: 1.5, learning_rate: 0.000, weight_decay: 0.000, external_signal_dim: HNM_ARTIFACT_EXTERNAL_SIGNAL_DIM, external_signal_role: "add_to_bu", verbose: HNM_VERBOSE }},
            { name: "L1_ContextualResonance", dim: STATE_VECTOR_SIZE, bu_source_level_names: ["L0_IntentProcessing"], td_source_level_names: [], external_input_config: { source_signal_name: "ActiveGenreRuleSignal", dim: HNM_GENRE_RULE_EXTERNAL_SIGNAL_DIM }, nmm_params: { mem_model_depth: 2, mem_model_expansion: 2.0, learning_rate: 0.000, weight_decay: 0.000, external_signal_dim: HNM_GENRE_RULE_EXTERNAL_SIGNAL_DIM, external_signal_role: "add_to_target", verbose: HNM_VERBOSE }}
        ];
        const HNM_POLICY_HEAD_INPUT_LEVEL_NAME = "L1_ContextualResonance";

        const GENRE_TARGET_STATES = { 
            "PSY_CHILL":      [0.5,0.2,0.3,0.7,0.5,0.7,0.3,0.2,0.3,0.2,0.7,0.6,0.1,0.5,0.2,0.6,0.4,0.5,0.3,0.5,0.5,0.2,0.6,0.3,0.2,0.3,0.4,0.2,0.4,0.4,0.5,0.6,0.4,0.5,0.7,0.6,0.2,0.5,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
            "PSY_DUB":        [0.6,0.3,0.2,0.4,0.6,0.6,0.4,0.2,0.4,0.35,0.6,0.5,0.2,0.7,0.3,0.7,0.3,0.4,0.2,0.6,0.2,0.1,0.7,0.4,0.3,0.4,0.3,0.3,0.5,0.5,0.3,0.7,0.6,0.6,0.8,0.7,0.3,0.6,0.3,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
            "PSY_PROGRESSIVE":[0.5,0.6,0.4,0.6,0.5,0.5,0.6,0.4,0.6,0.55,0.4,0.5,0.3,0.4,0.6,0.65,0.6,0.5,0.4,0.5,0.5,0.4,0.5,0.5,0.4,0.5,0.5,0.4,0.4,0.4,0.4,0.4,0.3,0.4,0.5,0.4,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
            "PSY_FULLON":     [0.7,0.7,0.5,0.3,0.6,0.4,0.7,0.6,0.7,0.75,0.3,0.4,0.4,0.3,0.7,0.3,0.8,0.6,0.6,0.4,0.4,0.6,0.4,0.6,0.5,0.6,0.7,0.3,0.3,0.3,0.3,0.3,0.2,0.3,0.4,0.3,0.5,0.4,0.6,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
            "DARK_PSY_CHILL": [0.4,0.3,0.6,0.2,0.6,0.1,0.5,0.4,0.5,0.4,0.5,0.4,0.5,0.6,0.3,0.6,0.5,0.6,0.5,0.4,0.4,0.3,0.5,0.4,0.4,0.4,0.4,0.3,0.4,0.4,0.4,0.5,0.3,0.5,0.6,0.5,0.3,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
            "DARK_PSY_DUB":   [0.5,0.2,0.7,0.3,0.7,0.2,0.5,0.3,0.6,0.45,0.5,0.3,0.6,0.7,0.2,0.65,0.4,0.5,0.4,0.5,0.3,0.2,0.6,0.5,0.4,0.5,0.4,0.2,0.4,0.4,0.3,0.6,0.5,0.5,0.7,0.6,0.4,0.5,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
            "DARK_PSY_PROG":  [0.4,0.5,0.6,0.4,0.6,0.3,0.7,0.5,0.8,0.65,0.3,0.3,0.6,0.6,0.4,0.7,0.6,0.6,0.7,0.4,0.3,0.5,0.4,0.6,0.5,0.6,0.5,0.2,0.3,0.3,0.3,0.3,0.2,0.3,0.4,0.3,0.5,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
            "DARK_PSY":       [0.8,0.4,0.7,0.3,0.7,0.2,0.8,0.8,0.9,0.85,0.4,0.2,0.7,0.8,0.2,0.75,0.7,0.7,0.8,0.3,0.3,0.8,0.2,0.7,0.6,0.7,0.6,0.2,0.2,0.2,0.2,0.2,0.1,0.2,0.3,0.2,0.6,0.3,0.7,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],
        };
        for (const key in GENRE_TARGET_STATES) { if (GENRE_TARGET_STATES[key] && GENRE_TARGET_STATES[key].length !== STATE_VECTOR_SIZE) { console.warn(`Genre ${key} target state has incorrect length ${GENRE_TARGET_STATES[key].length}, expected ${STATE_VECTOR_SIZE}. Padding/truncating.`); const correctLengthArray = new Array(STATE_VECTOR_SIZE).fill(0.5); for(let i=0; i < STATE_VECTOR_SIZE; i++) { if (GENRE_TARGET_STATES[key][i] !== undefined && typeof GENRE_TARGET_STATES[key][i] === 'number') { correctLengthArray[i] = clamp(GENRE_TARGET_STATES[key][i], 0, 1); } } GENRE_TARGET_STATES[key] = correctLengthArray; } else if (GENRE_TARGET_STATES[key]) { GENRE_TARGET_STATES[key] = GENRE_TARGET_STATES[key].map(v => clamp(v,0,1)); } }

        let renderer, scene, camera, audioContext, masterGain, analyserNode;
        let inputProcessorModel;
        let hnmSystem, hnmMemoryStates, hnmLastStepOutputs;
        let graphicsController, audioController, artifactManager, embeddingProvider, featureExtractor, speechController;
        let interactionOccurred = false; let embeddingsReady = false; let lastArtifactCreationTime = 0;
        let complexityLevel = 0.5; 
        let lastFpsTime = 0; let frameCount = 0; let currentFPS = TARGET_FPS;
        let currentInputState = { touch: { x: 0.5, y: 0.5, active: false, pressure: 0, dx: 0, dy: 0, lastX: 0.5, lastY: 0.5 }, motion: { alpha: 0, beta: 0, gamma: 0, available: false }, mic: { level: 0, fft: new Float32Array(MIC_FFT_SIZE / 2).fill(-140), available: false, rhythmPeak: 0, rhythmTempo: 0 }, accelerometer: { x: 0, y: 0, z: 0, magnitude: 0, available: false, history: new Array(ACCEL_FFT_SIZE).fill(0), rhythmPeak: 0, rhythmTempo: 0 }, syncFactor: 0.0, currentTime: 0.0 };
        let currentResonantState = tf.keep(tf.fill([1, 1, STATE_VECTOR_SIZE], 0.5)); 
        let activeArtifactInfo = { ids: [], stateArrays: [], similarities: [] };
        let resetGestureState = { pointerDownTime: 0, longPressDetected: false, longPressReleaseTime: 0, resetTimeout: null };
        let lastAccelTime = 0;
        let visualFeedback = { active: false, intensity: 0, startTime: 0, duration: 0.1 };
        let memoryInfo = { numBytes: 0, numTensors: 0 };
        let stateLoadAttempted = false; let stateLoadSucceeded = false;

        let gui;
        const menuSettings = {
            playerInfluence: 0.5, genreRuleInfluence: 0.5, micFeedbackToL0Strength: 0.25, explorationInfluence: 0.1,
            psySpectrumPosition: 0.5, darknessModifier: 0.0,
            masterBPM: 140,
            kickTune: 0.5, kickPunch: 0.7, kickDecay: 0.2, kickClick: 0.5, kickLevel: 0.8,
            bassOscType: 0, bassOctave: 0.3, bassCutoff: 0.3, bassReso: 0.6, bassEnvAmt: 0.7, bassFilterDecay: 0.15, bassAmpDecay: 0.1, bassFilterLfoRate: 0.2, bassFilterLfoDepth: 0.3, bassLevel: 0.7,
            leadOscType: 0, leadOctave: 0.6, leadPW: 0.5, leadCutoff: 0.6, leadReso: 0.7, leadEnvAmt: 0.8, leadFilterDecay: 0.3, leadAmpDecay: 0.4, leadPitchLfoRate: 0.5, leadPitchLfoDepth: 0.3, leadFilterLfoRate: 0.3, leadFilterLfoDepth: 0.4, leadLevel: 0.6,
            hatClosedDecay: 0.05, hatOpenDecay: 0.25, hatHpfCutoff: 0.7, hatTone: 0.5, hatLevel: 0.5,
            snareNoiseLevel: 0.8, snareNoiseDecay: 0.08, snareBodyTune: 0.5, snareBodyDecay: 0.15, snareBodyLevel: 0.5, snareLevel: 0.6,
            noiseFxFiltType: 0, noiseFxCutoff: 0.5, noiseFxReso: 0.4, noiseFxLfoRate: 0.3, noiseFxLfoDepth: 0.6, noiseFxLevel: 0.4, 
            delayTimeMode: 2, delayFeedback: 0.45, delayMix: 0.3,
            reverbSize: 0.7, reverbDamp: 0.5, reverbMix: 0.25,
            enableSpeechCommands: true, enableTapReset: true,
            resetMenuToDefaults: () => { resetMenuSettingsToDefault(); showWarning("Menu settings reset to default.", 2000); },
            resetHnmRag: () => { console.log("HNM/RAG Reset triggered from lil-gui button."); showWarning("Resetting HNM/RAG State (menu settings preserved)...", 1500); document.getElementById('resetButton').click(); },
            genreEdit_Selected: "PSY_CHILL", _genreEdit_tempState: new Array(STATE_VECTOR_SIZE).fill(0.5),
            genreEdit_Param0: 0.5, genreEdit_Param1: 0.5, genreEdit_Param2: 0.5, genreEdit_Param3: 0.5,
            genreEdit_Param4: 0.5, genreEdit_Param5: 0.5, genreEdit_Param6: 0.5, genreEdit_Param7: 0.5,
            genreEdit_Param8: 0.5, genreEdit_Param9: 0.5, genreEdit_Param10: 0.5, genreEdit_Param11: 0.5,
            genreEdit_Param12: 0.5, genreEdit_Param13: 0.5, genreEdit_Param14: 0.5, genreEdit_Param15: 0.5,
            genreEdit_LoadToSliders: () => { loadSelectedGenreToSliders(); },
            genreEdit_SaveToSelected: () => { saveSlidersToSelectedGenre(); }
        };
        const GENRE_EDIT_SLIDER_COUNT = 16; 
        const GENRE_EDIT_SLIDER_MAPPING = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]; 

        const defaultMenuSettings = JSON.parse(JSON.stringify(menuSettings)); 
        delete defaultMenuSettings.resetMenuToDefaults; delete defaultMenuSettings.resetHnmRag;
        delete defaultMenuSettings.genreEdit_LoadToSliders; delete defaultMenuSettings.genreEdit_SaveToSelected;
        delete defaultMenuSettings._genreEdit_tempState;

        let currentGenreRuleVector = null; 

        function analyzeRhythm(data, sampleRateOrFreq, dataSize) { let peakFreqBin = -1; let peakMag = -Infinity; let totalEnergy = 0; const freqResolution = (sampleRateOrFreq / 2) / (dataSize / 2); for (let i = 0; i < data.length; i++) { const magnitude = data[i]; const linearMag = isFinite(magnitude) ? (magnitude > -100 ? Math.pow(10, magnitude / 20) : 0) : 0; totalEnergy += linearMag * linearMag; const freq = i * freqResolution; if (magnitude > peakMag && freq >= 1.0 && freq <= 10.0) { peakMag = magnitude; peakFreqBin = i; } } const peakFrequency = peakFreqBin * freqResolution; let normalizedPeak; if (sampleRateOrFreq > 1000) { normalizedPeak = clamp((peakMag + 80.0) / 80.0, 0, 1); } else { const rmsEnergy = data.length > 0 ? Math.sqrt(totalEnergy / data.length) : 0; normalizedPeak = clamp(rmsEnergy / 5.0, 0, 1); } const estimatedTempo = clamp(peakFrequency * 60, 60, 240); if (peakFreqBin === -1) { return { peak: normalizedPeak, tempo: 120 }; } return { peak: normalizedPeak, tempo: estimatedTempo }; }
        class FeatureExtractor { constructor(stateVectorSize) { this.stateVectorSize = stateVectorSize; this.indices = { kick: 0, arpSpeed: 1, bassCut: 2, bright: 3, sat: 4, hue: 5, flow: 6, warp: 7, complexity: 8, tempo: 9, reverb: 10, leadDecay: 11, noiseLevel: 12, noiseCut: 13, noiseRes: 14, masterVol: 15, leadPresence: 16, leadOctave: 17, leadPitchMod: 18, leadPattern: 19, bassOctave: 20, leadLfoRate: 21, bassDecay: 22, hat1Level: 23, noiseLfoSpeed: 24, hat2Level: 25, hatPattern: 26, snarePresence: 27, hatDecay1: 28, hatDecay2: 29, hatHpCutoff: 30, delayTime: 31, delayFeedback: 32, delayMix: 33, combFeedback: 34, combDamping: 35, fxLfoRate: 36, apFeedback: 37, snareTone: 38 }; } _getCategory(v, thresholds, labels) { for (let i = 0; i < thresholds.length; i++) { if (v < thresholds[i]) return labels[i]; } return labels[labels.length - 1]; } extractTags(arr) { if (!arr || arr.length !== this.stateVectorSize) { console.warn(`FeatureExtractor: Invalid array provided (length ${arr?.length}, expected ${this.stateVectorSize})`); return ""; } const tags = new Set(); const i = this.indices; const getVal = (idx, def) => (idx !== undefined && arr[idx] !== undefined && typeof arr[idx] === 'number' && isFinite(arr[idx])) ? arr[idx] : def; const tempoVal = getVal(i.tempo, 0.5); tags.add(this._getCategory(tempoVal, [0.25, 0.5, 0.75], ["slow", "mid", "fast", "very_fast"])); if (getVal(i.kick, 0.5) > 0.75) tags.add("drive"); const bc = getVal(i.bassCut, 0.5); const br = getVal(i.bright, 0.5); if (bc < 0.3 && br > 0.6) tags.add("dark_bass"); else if (bc > 0.5 && br > 0.7) tags.add("acidic"); else if (bc > 0.4) tags.add("bright_bass"); if (getVal(i.sat, 0.5) > 0.65) tags.add("saturated"); if (getVal(i.leadPresence, 0.5) > 0.6) { const leadDecayVal = getVal(i.leadDecay, 0.1); if (leadDecayVal < 0.15) tags.add("plucky_lead"); else tags.add("long_lead"); } if (getVal(i.noiseLevel, 0.1) > 0.3) tags.add("noisy"); const comp = getVal(i.complexity, 0.5); tags.add(this._getCategory(comp, [0.4, 0.8], ["simple", "mid", "complex"])); const hueVal = getVal(i.hue, 0.5); tags.add(this._getCategory(hueVal, [0.15, 0.3, 0.45, 0.6, 0.75, 0.9], ["red", "orange", "yellow", "green", "blue", "purple", "red"])); if (getVal(i.flow, 0.0) > 0.7) tags.add("flow"); if (getVal(i.warp, 0.0) > 0.6) tags.add("warp"); if (getVal(i.reverb, 0.0) > 0.5) tags.add("reverb"); const vol = getVal(i.masterVol, 0.6); if (vol < 0.3) tags.add("quiet"); else if (vol > 0.8) tags.add("loud"); if (getVal(i.snarePresence, 0.5) > 0.6) tags.add("snare"); return Array.from(tags).join(' '); } }
        class EmbeddingProvider { constructor(modelName) { this.modelName = modelName; this.pipeline = null; this.isInitializing = false; this.loadingDiv = document.getElementById('loadingInfo'); this.loadingProgress = document.getElementById('loadingProgress'); } async init() { if (this.pipeline || this.isInitializing) return; this.isInitializing = true; showLoading(true, `Loading Embedding: ${this.modelName}...`); console.log(`Loading model: ${this.modelName}...`); try { const { pipeline, env } = await import('@xenova/transformers'); env.allowLocalModels = false; env.allowRemoteModels = true; env.backends.onnx.wasm.numThreads = 1; env.backends.onnx.wasm.simd = true; console.log("Transformer env configured."); this.pipeline = await pipeline('feature-extraction', this.modelName, { quantized: true, progress_callback: (p) => { if (this.loadingProgress) { let s=p.status; if(p.file) s+=`: ${p.file}`; if(p.loaded&&p.total){s+=` (${((p.loaded/p.total)*100).toFixed(1)}%)`;} this.loadingProgress.textContent=s; } } }); console.log("Embedding pipeline loaded."); embeddingsReady = true; showLoading(false); if (!stateLoadAttempted || stateLoadSucceeded) showWarning("System Ready. Interact or Speak. Say 'Reset Echoes' to reset.", 6000); } catch (e) { console.error("FATAL: Embedding model failed:", e); showError("Embedding Model Failed! Artifacts disabled."); embeddingsReady = false; showLoading(false); artifactManager = null; if (e.message && e.message.includes("CacheStorage")) { console.warn("Note: CacheStorage error detected during embedding model load. This is often a browser issue and may resolve itself. Functionality might be okay unless model loading fully failed."); showWarning("Warning: Browser cache issue detected (Embeddings).", 7000); } } finally { this.isInitializing = false; } } async embed(text) { if (!this.pipeline || !embeddingsReady) return null; if (!text || typeof text !== 'string' || text.trim().length === 0) { console.warn("Embed skip: Invalid text."); return null; } try { const r = await this.pipeline(text, { pooling: 'mean', normalize: true }); if (r && r.data && r.data.length === EMBEDDING_DIM) return r.data; else { console.warn("Embed failed/bad shape:", text); return null; } } catch (e) { console.error("Embedding error:", e); return null; } } }
        class ArtifactManager { constructor(maxArtifacts, stateVectorSize, embeddingDim, featureExtractor, embeddingProvider) { this.maxArtifacts=maxArtifacts; this.stateVectorSize=stateVectorSize; this.embeddingDim=embeddingDim; this.featureExtractor=featureExtractor; this.embeddingProvider=embeddingProvider; this.artifacts=[]; this.nextId=0; } async createArtifact(stateVectorTensor) { if (!embeddingsReady || !this.featureExtractor || !this.embeddingProvider) return false; if (!stateVectorTensor || stateVectorTensor.isDisposed) { console.warn("Artifact create skip: Invalid tensor."); return false; } const stateArr = await stateVectorTensor.squeeze([0,1]).data(); const tags = this.featureExtractor.extractTags(stateArr); if (!tags) return false; const emb = await this.embeddingProvider.embed(tags); if (!emb || emb.length !== this.embeddingDim) return false; const newArt = { id: this.nextId++, stateVector: Array.from(stateArr), featureTags: tags, embedding: emb, timestamp: Date.now() }; this.artifacts.push(newArt); console.log(`Artifact ${newArt.id} created: "${tags.substring(0,50)}..."`); triggerVisualFeedback(0.6); if (this.artifacts.length > this.maxArtifacts) { this.artifacts.sort((a,b) => a.timestamp - b.timestamp); const removed = this.artifacts.shift(); console.log(`Pruned oldest artifact ${removed.id}. Count: ${this.artifacts.length}`); } saveStateToLocalStorage(); return true; } _cosineSimilarity(a,b) { if (!a||!b||a.length !== b.length||a.length===0) return 0; let dot=0, nA=0, nB=0; for (let i=0; i<a.length; i++) { dot+=a[i]*b[i]; nA+=a[i]*a[i]; nB+=b[i]*b[i]; } if (nA===0||nB===0) return 0; return dot / ((Math.sqrt(nA)*Math.sqrt(nB))+1e-9); } async findRelevantArtifacts(stateTensor, thresh, maxCnt) { const result = { ids:[], stateArrays:[], similarities:[] }; if (!embeddingsReady || this.artifacts.length===0 || !stateTensor || stateTensor.isDisposed) return result; const stateArr = await stateTensor.squeeze([0,1]).data(); const tags = this.featureExtractor.extractTags(stateArr); if (!tags) return result; const queryEmb = await this.embeddingProvider.embed(tags); if (!queryEmb) return result; const candidates = this.artifacts.map(art => ({ art: art, similarity: this._cosineSimilarity(queryEmb, art.embedding) })); const relevant = candidates.filter(c => c.similarity >= thresh).sort((a,b) => b.similarity - a.similarity); const selected = relevant.slice(0, maxCnt); selected.forEach(item => { result.ids.push(item.art.id); result.stateArrays.push(item.art.stateVector); result.similarities.push(item.similarity); }); return result; } getArtifactCount() { return this.artifacts.length; } setArtifacts(loaded) { if (!Array.isArray(loaded)) { console.error("Cannot set artifacts: input is not an array.", loaded); this.artifacts = []; this.nextId = 0; return; } this.artifacts = loaded.filter(a => a && typeof a === 'object').map(a => { const id = typeof a.id === 'number' ? a.id : 0; const stateVector = Array.isArray(a.stateVector) && a.stateVector.length === this.stateVectorSize ? a.stateVector.map(v => typeof v === 'number' && isFinite(v) ? clamp(v, 0, 1) : 0.5) : new Array(this.stateVectorSize).fill(0.5); const featureTags = typeof a.featureTags === 'string' ? a.featureTags : ''; const embedding = Array.isArray(a.embedding) && a.embedding.length === this.embeddingDim ? a.embedding.map(v => typeof v === 'number' && isFinite(v) ? v : 0) : new Array(this.embeddingDim).fill(0); const timestamp = typeof a.timestamp === 'number' ? a.timestamp : Date.now(); if (!Array.isArray(a.stateVector) || a.stateVector.length !== this.stateVectorSize) { console.warn(`Loaded artifact ${id} had invalid stateVector (size ${a.stateVector?.length}), using default.`); } if (!Array.isArray(a.embedding) || a.embedding.length !== this.embeddingDim) { console.warn(`Loaded artifact ${id} had invalid embedding (size ${a.embedding?.length}), using default.`); } return { id, stateVector, featureTags, embedding, timestamp }; }).filter(a => a !== null); this.nextId = this.artifacts.reduce((maxId, art) => Math.max(maxId, art.id), -1) + 1; console.log(`Loaded ${this.artifacts.length} validated artifacts. Next ID: ${this.nextId}`); } forgetOldestArtifact() { if (this.artifacts.length > 0) { this.artifacts.sort((a, b) => a.timestamp - b.timestamp); const removed = this.artifacts.shift(); console.log(`Forgot oldest artifact ${removed.id} via command.`); triggerVisualFeedback(0.3, 0.2); saveStateToLocalStorage(); return true; } console.log("No artifacts to forget."); return false; } }
        class SpeechRecognitionController { constructor() { this.recognition = null; this.isSupported = ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window); this.isListening = false; this.isActive = false; this.isStarting = false; this.isStopping = false; this.permissionGranted = false; this.statusDiv = document.getElementById('speechStatus'); this.commandCallback = null; this.consecutiveErrorCount = 0; this.MAX_CONSECUTIVE_ERRORS = 8; this.restartTimeoutId = null; if (!this.isSupported) { console.warn("Speech Recognition API not supported."); this.updateStatus("Unsupported"); } } updateStatus(status) { if (this.statusDiv) { this.statusDiv.textContent = `Speech: ${status}`; this.statusDiv.style.display = 'block'; } return status; } async requestPermissionAndInit() { if (!this.isSupported || this.recognition) return; try {  await navigator.mediaDevices.getUserMedia({ audio: true }); this.permissionGranted = true; console.log("Audio permission likely granted for Speech Rec."); this.initializeRecognition(); } catch (err) { console.error("Mic permission denied or failed for Speech Rec:", err.name, err.message); this.updateStatus("Perm Denied"); if (interactionOccurred) showWarning("Voice commands disabled: Mic permission needed.", 5000); this.permissionGranted = false; } } initializeRecognition() { if (!this.isSupported || !this.permissionGranted || this.recognition) return; const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition; this.recognition = new SpeechRecognition(); this.recognition.continuous = true; this.recognition.interimResults = false; this.recognition.lang = 'en-US'; this.recognition.maxAlternatives = 1; this.recognition.onstart = () => { console.log("Speech recognition actually started."); this.isActive = true; this.isStarting = false; this.updateStatus("Listening"); }; this.recognition.onend = () => { console.log("Speech recognition ended."); this.isActive = false; this.isStarting = false; this.isStopping = false; if (this.isListening && menuSettings.enableSpeechCommands) { console.log("...restarting listening after short delay."); this.scheduleRestart(150 + Math.random() * 100); } else { this.updateStatus("Idle"); } }; this.recognition.onresult = (event) => { this.consecutiveErrorCount = 0; const last = event.results.length - 1; const transcript = event.results[last][0].transcript.trim().toLowerCase(); console.log(`Speech Result: "${transcript}"`); this.handleCommand(transcript); }; this.recognition.onerror = (event) => { console.error('Speech Recognition Error:', event.error); const error = event.error; this.isActive = false; this.isStarting = false; this.isStopping = false; let autoRestart = true; if (error === 'no-speech') { this.updateStatus("Quiet"); this.consecutiveErrorCount++; } else if (error === 'audio-capture') { this.updateStatus("Mic Problem"); this.consecutiveErrorCount++; } else if (error === 'network') { this.updateStatus("Network Issue"); this.consecutiveErrorCount++; } else if (error === 'not-allowed' || error === 'service-not-allowed') { this.updateStatus("Blocked/Disabled"); this.permissionGranted = false; this.isListening = false; autoRestart = false; showError(`Voice commands ${error}! Check permissions.`); } else { this.updateStatus(`Error (${error})`); this.consecutiveErrorCount++; } if (this.consecutiveErrorCount > this.MAX_CONSECUTIVE_ERRORS) { console.error("Too many consecutive speech errors, stopping attempts."); this.updateStatus("Stopped (Errors)"); this.isListening = false; autoRestart = false; showWarning("Speech recognition stopped due to repeated errors.", 6000); } if (this.isListening && menuSettings.enableSpeechCommands && autoRestart) { this.scheduleRestart(750 + Math.random() * 500); } }; console.log("Speech Recognition initialized."); this.updateStatus("Initialized"); } setCommandCallback(callback) { this.commandCallback = callback; } scheduleRestart(delay) { if (this.restartTimeoutId) clearTimeout(this.restartTimeoutId); this.restartTimeoutId = setTimeout(() => { this.restartTimeoutId = null; console.log("Executing scheduled speech restart."); this.startListening(); }, delay); }
            startListening() { if (!menuSettings.enableSpeechCommands || !this.isSupported || this.isActive || this.isStarting || this.isStopping) return; if (!this.permissionGranted) { console.log("Speech start deferred: Requesting permission first."); this.requestPermissionAndInit().then(() => { if (this.permissionGranted) { this.startListening(); } }); return; } if (!this.recognition) { console.warn("Speech start failed: Recognition not initialized."); return; } console.log("Attempting to start speech recognition..."); this.isListening = true; this.isStarting = true; this.updateStatus("Starting..."); try { if (this.restartTimeoutId) { clearTimeout(this.restartTimeoutId); this.restartTimeoutId = null; } this.recognition.start(); } catch (e) { console.error("Error executing recognition.start():", e); this.isListening = false; this.isStarting = false; this.isActive = false; this.updateStatus("Start Failed"); if (e.name === 'InvalidStateError') { console.warn("InvalidStateError caught, likely rapid start/stop. Waiting for onend."); } else { this.scheduleRestart(1000 + Math.random() * 500); } } }
            stopListening() { console.log("Attempting to stop speech recognition..."); this.isListening = false; if (this.restartTimeoutId) { clearTimeout(this.restartTimeoutId); this.restartTimeoutId = null; } if (!this.recognition || (!this.isActive && !this.isStarting) || this.isStopping) { if (!this.isActive && !this.isStarting) this.updateStatus("Idle"); return; } this.isStopping = true; this.updateStatus("Stopping"); try { this.recognition.stop(); } catch(e) { console.error("Error executing recognition.stop():", e); this.isStopping = false; this.isActive = false; this.updateStatus("Stop Failed"); } }
            handleCommand(transcript) { if (!menuSettings.enableSpeechCommands) return; let matchedCommand = null; const cleanTranscript = transcript.trim(); if (cleanTranscript.length === 0) return; for (const commandType in SPEECH_COMMANDS) { if (SPEECH_COMMANDS[commandType].some(phrase => cleanTranscript.includes(phrase))) { matchedCommand = commandType; console.log(`Matched Command: ${matchedCommand} from "${cleanTranscript}"`); break; } } if (matchedCommand && this.commandCallback) { this.commandCallback(matchedCommand); triggerVisualFeedback(0.2, 0.1); } else { console.log(`Unrecognized command: "${cleanTranscript}"`); } } }
        class PlaceholderInputProcessor { constructor(inputDim, outputDim) { this.inputDim = inputDim; this.outputDim = outputDim; } process(inputData, currentTime) { return tf.tidy(() => { const vec = new Array(this.outputDim).fill(0); const touchFactor = inputData.touch.active ? (inputData.touch.pressure || 1.0) : 0; const micLevel = inputData.mic.available ? inputData.mic.level : 0; const motionAvailable = inputData.motion.available; const alphaNorm = motionAvailable ? (inputData.motion.alpha / 360.0) % 1.0 : 0.5; const betaNorm = motionAvailable ? clamp((inputData.motion.beta + 180.0) / 360.0, 0, 1) : 0.5; const gammaNorm = motionAvailable ? clamp((inputData.motion.gamma + 90.0) / 180.0, 0, 1) : 0.5; const touchVelMag = clamp(Math.sqrt(inputData.touch.dx**2 + inputData.touch.dy**2) * 25, 0, 1); const accelAvailable = inputData.accelerometer.available; const accelNormX = accelAvailable ? clamp((inputData.accelerometer.x + 20) / 40, 0, 1) : 0.5; const accelNormY = accelAvailable ? clamp((inputData.accelerometer.y + 20) / 40, 0, 1) : 0.5; const accelNormZ = accelAvailable ? clamp((inputData.accelerometer.z + 20) / 40, 0, 1) : 0.5; const accelMagNorm = accelAvailable ? clamp(inputData.accelerometer.magnitude / 25, 0, 1) : 0; const micRhythmPeak = inputData.mic.available ? inputData.mic.rhythmPeak : 0; const micRhythmTempoNorm = inputData.mic.available ? clamp((inputData.mic.rhythmTempo - 60) / (240 - 60), 0, 1) : 0.5; const accelRhythmPeak = accelAvailable ? inputData.accelerometer.rhythmPeak : 0; const accelRhythmTempoNorm = accelAvailable ? clamp((inputData.accelerometer.rhythmTempo - 60) / (240 - 60), 0, 1) : 0.5; for (let i = 0; i < this.outputDim; i++) { switch (i % 16) { case 0: vec[i] = inputData.touch.x * (1.0 + touchFactor * 0.1); break; case 1: vec[i] = inputData.touch.y * (1.0 + touchFactor * 0.1); break; case 2: vec[i] = touchFactor; break; case 3: vec[i] = alphaNorm; break; case 4: vec[i] = betaNorm; break; case 5: vec[i] = gammaNorm; break; case 6: vec[i] = micLevel; break; case 7: vec[i] = touchVelMag; break; case 8: vec[i] = accelNormX; break; case 9: vec[i] = accelNormY; break; case 10: vec[i] = accelNormZ; break; case 11: vec[i] = accelMagNorm; break; case 12: vec[i] = micRhythmPeak; break; case 13: vec[i] = micRhythmTempoNorm; break; case 14: vec[i] = accelRhythmPeak; break; case 15: vec[i] = accelRhythmTempoNorm; break; } const prevVal = vec[(i + this.outputDim - 1) % this.outputDim] !== undefined ? vec[(i + this.outputDim - 1) % this.outputDim] : 0; const otherVal = vec[(i + 5) % this.outputDim] !== undefined ? vec[(i + 5) % this.outputDim] : 0; vec[i] = fract(vec[i]*1.1 + prevVal*0.3 + Math.sin(otherVal * 5.1 + i*0.1 + currentTime * 0.1) * 0.1); vec[i] = 1.0 / (1.0 + Math.exp(-(vec[i] * 2.0 - 1.0) * 1.8)); vec[i] = clamp(vec[i] || 0, 0, 1); } if (inputData.mic.available && inputData.mic.fft) { const fftData = inputData.mic.fft; const fftLen = fftData.length; const segments = 8; const binsPerSegment = Math.max(1, Math.floor(fftLen / segments)); for(let seg = 0; seg < segments; seg++) { let peakDb = -140; const start = seg * binsPerSegment; const end = Math.min(start + binsPerSegment, fftLen); for(let k = start; k < end; k++) { if(isFinite(fftData[k])) peakDb = Math.max(peakDb, fftData[k]); } const normPeak = clamp((peakDb + 100) / 100, 0, 1); const tIdxStart = this.outputDim - 1 - seg * 2; if (tIdxStart >= 0) vec[tIdxStart] = (vec[tIdxStart] * 0.5 + normPeak * 0.5); if (tIdxStart - 1 >= 0) vec[tIdxStart - 1] = (vec[tIdxStart - 1] * 0.3 + normPeak * 0.7); } } return tf.tensor1d(vec).expandDims(0).expandDims(0); }); } }
        class GraphicsController { constructor(canvas) { this.canvas = canvas; scene = new THREE.Scene(); camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 100); camera.position.z = 4; try { renderer = new THREE.WebGLRenderer({ canvas: this.canvas, antialias: true, powerPreference: "high-performance" }); } catch (e) { console.error("!!! Failed to create WebGLRenderer:", e); showError("WebGL Renderer Failed!"); throw e; } renderer.setSize(window.innerWidth, window.innerHeight); renderer.setPixelRatio(Math.min(window.devicePixelRatio, 1.6)); MAX_ARTIFACTS_SHADER = this.detectMaxUniformCapacity(); console.log(`Graphics: Detected max shader artifacts = ${MAX_ARTIFACTS_SHADER}`); const geometry = new THREE.PlaneGeometry(2, 2); this.material = new THREE.ShaderMaterial({ defines: { MAX_ARTIFACTS_SHADER: MAX_ARTIFACTS_SHADER, STATE_VEC_SIZE: STATE_VECTOR_SIZE }, uniforms: { time: { value: 0.0 }, resolution: { value: new THREE.Vector2(window.innerWidth * renderer.getPixelRatio(), window.innerHeight * renderer.getPixelRatio()) }, mainState: { value: new Float32Array(STATE_VECTOR_SIZE).fill(0.5) }, numActiveArtifacts: { value: 0 }, artifactStates: { value: this._createArtifactUniformArray() }, artifactSimilarities: { value: new Float32Array(MAX_ARTIFACTS_SHADER).fill(0.0) }, complexity: { value: complexityLevel }, syncFactor: { value: 0.0 }, feedbackIntensity: { value: 0.0 } }, vertexShader: `varying vec2 vUv; void main() { vUv = uv; gl_Position = vec4(position.xy, 0.0, 1.0); }`, fragmentShader: `
                        precision highp float;
                        uniform float time; uniform vec2 resolution; uniform float mainState[STATE_VEC_SIZE];
                        uniform int numActiveArtifacts;
                        uniform float artifactStates[MAX_ARTIFACTS_SHADER * STATE_VEC_SIZE];
                        uniform float artifactSimilarities[MAX_ARTIFACTS_SHADER];
                        uniform float complexity; uniform float syncFactor; uniform float feedbackIntensity;
                        varying vec2 vUv;
                        #define PI 3.14159265359
                        #define STATE_VEC_SIZE_FLOAT float(STATE_VEC_SIZE)
                        float hash1(float n){ return fract(sin(n)*43758.5453); }
                        vec2 hash2(vec2 p){ p=vec2(dot(p,vec2(127.1,311.7)),dot(p,vec2(269.5,183.3))); return -1.+2.*fract(sin(p)*43758.5453); }
                        float noise(vec2 x){ vec2 p=floor(x); vec2 f=fract(x); f=f*f*(3.-2.*f); float n=p.x+p.y*57.; return mix(mix(hash1(n),hash1(n+1.),f.x),mix(hash1(n+57.),hash1(n+58.),f.x),f.y); }
                        float fbm(vec2 p, float H, int octaves){ float G=exp2(-H); float f=1.; float a=1.; float t=0.; for(int i=0; i<10; i++){ if(i>=octaves) break; t+=a*noise(f*p); f*=2.; a*=G; } return t; }
                        vec3 hsv2rgb(vec3 c){ vec4 K=vec4(1.,2./3.,1./3.,3.); vec3 p=abs(fract(c.xxx+K.xyz)*6.-K.www); return c.z*mix(K.xxx,clamp(p-K.xxx,0.,1.),c.y); }
                        float pulse(float t, float freq){ return 0.5+0.5*cos(t*freq*2.*PI); }
                        mat2 rotate2d(float a){ float s=sin(a); float c=cos(a); return mat2(c,-s,s,c); }
                        float getArtifactState(int artIdx, int stateIdx){ if(artIdx < 0 || artIdx >= MAX_ARTIFACTS_SHADER || stateIdx < 0 || stateIdx >= STATE_VEC_SIZE) return 0.5; int flatIdx = artIdx * STATE_VEC_SIZE + stateIdx; return artifactStates[flatIdx]; }
                        float getMainStateSafe(int idx, float defaultVal) { if (idx >= 0 && idx < STATE_VEC_SIZE) { return mainState[idx]; } return defaultVal; }
                        void main() { vec2 uv = vUv; vec2 centerUv = uv - 0.5; float distCenter = length(centerUv); float kick = getMainStateSafe(0, 0.5); float arpSpeed = 0.1 + getMainStateSafe(1, 0.5) * 2.5; float bassCut = getMainStateSafe(2, 0.5); float bright = 0.1 + getMainStateSafe(3, 0.5) * 0.7; float sat = 0.3 + getMainStateSafe(4, 0.5) * 0.7; float hueBase = getMainStateSafe(5, 0.5); float flowSpeed = 0.02 + getMainStateSafe(6, 0.0) * 0.45 * (0.5 + complexity * 1.5); float warpAmt = getMainStateSafe(7, 0.0) * 0.55 * (0.5 + complexity * 1.8); float compVal = getMainStateSafe(8, 0.5); float tempo = 80. + getMainStateSafe(9, 0.5) * 160.; float reverb = getMainStateSafe(10, 0.2) * (0.6 + complexity * 0.8); float leadDecay = getMainStateSafe(11, 0.5); float noiseInt = getMainStateSafe(12, 0.1) * 1.1 * (0.4 + complexity * 1.6); float vignette = 0.15 + getMainStateSafe(13, 0.5) * 0.8; float pulseInt = getMainStateSafe(14, 0.5) * 0.9; float masterVol = getMainStateSafe(15, 0.6); float grain = getMainStateSafe(20, 0.0) * 0.12 * (0.3 + complexity * 1.7); float rotationSpeed = (getMainStateSafe(21, 0.5) - 0.5) * 0.25 * (0.5 + complexity * 1.5); float compH = 0.3 + compVal * 0.6 * (0.3 + complexity * 1.2); int compOct = 1 + int(compVal * 6.0 * (0.4 + complexity * 1.4)); compOct = clamp(compOct, 1, 9); float globalPulse = pulse(time, 0.08 + complexity * 0.1); float globalRot = time * rotationSpeed; vec2 rotatedUv = rotate2d(globalRot) * centerUv + 0.5; float n = fbm(rotatedUv * (2.0 + complexity * 1.0) + time * 0.05, 0.5, 3); vec2 flowVec = vec2(cos(time * flowSpeed + globalPulse * 0.8), sin(time * flowSpeed * 1.2 + n * 0.1)) * (0.4 + complexity * 0.5); vec2 warpDir = hash2(rotatedUv * (2.5 + complexity * 1.5) + time * (0.05 + complexity * 0.1)); float warpEffect = warpAmt * (0.6 + noise(rotatedUv * (2.0+complexity*2.0) + time * (0.03+complexity*0.05)) * 0.4) * pow(1.0 - distCenter * 1.1, 2.8) * (1.0 + complexity * 1.2); vec2 warpOffset = warpDir * warpEffect; vec2 warpedUv = (rotatedUv - 0.5) * (1.0 - bassCut * 0.2 + kick * 0.1) + 0.5 + warpOffset; float baseFreq = 1.5 + arpSpeed * 4.0 * (0.7 + complexity * 0.6); n = fbm(warpedUv * baseFreq + flowVec + time*(0.02 + complexity * 0.04), compH, compOct); float hue = fract(hueBase + time * (0.02 + complexity * 0.03) + n * (0.08 + complexity*0.1) - bassCut * 0.25 + syncFactor * 0.15); float beatPulse = pulse(time, tempo / 60.0); float kickPulse = beatPulse * pow(kick, 1.8) * pulseInt; float finalBright = bright * (1.0 + kickPulse * 1.0 - pulseInt * 0.3 + masterVol * 0.3 + globalPulse * 0.15); finalBright *= pow(max(0., 1.0 - distCenter * distCenter * vignette * 3.0), 1.8); finalBright += (hash1(time * (15.0 + complexity * 10.0)) - 0.5) * (0.02 + complexity * 0.03); float trailEffect = reverb * leadDecay * (0.15 + complexity * 0.2); float trailN = fbm(warpedUv * (baseFreq*0.7) + flowVec*0.6 - time*0.03, compH*0.7, compOct-1); vec3 trailColor = hsv2rgb(vec3(fract(hue + 0.15 + complexity * 0.1), sat * 0.7, finalBright * 0.5)); vec3 finalColor = hsv2rgb(vec3(hue, sat, finalBright)) + trailColor * trailEffect * smoothstep(0.35, 0.65, trailN); for(int i = 0; i < numActiveArtifacts; ++i) { if (i >= MAX_ARTIFACTS_SHADER) break; float sim = artifactSimilarities[i]; if(sim <= 0.05) continue; float artHueBase = getArtifactState(i, 5); float artSat = 0.3 + getArtifactState(i, 4) * 0.8; float artBright = 0.1 + getArtifactState(i, 3) * 0.8 * (0.6 + complexity * 0.7); float artTempo = 80. + getArtifactState(i, 9) * 160.; float artKick = getArtifactState(i, 0); float artCompVal = getArtifactState(i, 8); float artFlowSpeed = 0.01 + getArtifactState(i, 6) * 0.4 * (0.8 + complexity); float artSeed = hash1(float(i) * 1.37 + getArtifactState(i, 30)); float maskFreq = 2.0 + float(i) * 2.0 + artSeed * 3.0 + artCompVal * 4.0 * (0.8 + complexity * 0.5); float maskTime = time * 0.05 * (0.5 + float(i+1) * 0.7 + artSeed * 0.8 + artFlowSpeed * 6.0) * (0.8 + complexity * 0.8); float artMask = noise(rotatedUv * maskFreq + maskTime + artSeed * 7.0); artMask = smoothstep(0.38, 0.62, artMask); artMask *= sim * (0.6 + complexity * 0.8); float artHue = fract(artHueBase + time * (0.01 + complexity*0.01) + n * 0.05 + artSeed * 0.2); vec3 artColor = hsv2rgb(vec3(artHue, artSat, artBright * (1.0 + artKick * 0.6) )); finalColor = mix(finalColor, artColor, artMask * clamp(0.4 + complexity * 0.7, 0.1, 0.95)); float artBeatPulse = pulse(time, artTempo / 60.0); float echoIntensity = artBeatPulse * pow(artKick, 1.6) * sim * clamp(0.3 + complexity * 0.9, 0.1, 0.85); finalColor += vec3(echoIntensity * artMask) * artColor * 2.5; } finalColor += (hash1(dot(rotatedUv, vec2(12.9898, 78.233)) + time*(1.5 + complexity*0.5)) - 0.5) * grain * noiseInt * (0.8 + complexity * 0.8); finalColor = mix(finalColor, vec3(0.6, 0.7, 0.9), syncFactor * 0.15); finalColor += feedbackIntensity * vec3(1.0, 1.0, 0.9); gl_FragColor = vec4(clamp(finalColor, 0.0, 1.0), 1.0); } ` }); const mesh = new THREE.Mesh(geometry, this.material); scene.add(mesh); try { const gl = renderer.getContext(); const maxVec = gl.getParameter(gl.MAX_FRAGMENT_UNIFORM_VECTORS); console.log(`Max Fragment Uniform Vectors: ${maxVec}`); const neededVec = Math.ceil(STATE_VECTOR_SIZE / 4) + MAX_ARTIFACTS_SHADER * Math.ceil(STATE_VECTOR_SIZE / 4) + Math.ceil(MAX_ARTIFACTS_SHADER / 4) + 25; console.log(`Estimated Needed Vectors: ~${neededVec}`); if (maxVec < neededVec) { console.warn(`Potential Uniform Limit Issue: Max uniforms (${maxVec}) might be less than estimated need (~${neededVec}). Reducing shader artifacts might help.`); } } catch (e) { console.warn("Could not get WebGL uniform limits."); } } detectMaxUniformCapacity() { let detectedMax = 1; try { const gl = renderer.getContext(); if (!gl) { console.warn("Detect uniform capacity: No GL context available yet."); return 1; } const maxUniformVectors = gl.getParameter(gl.MAX_FRAGMENT_UNIFORM_VECTORS); const baseVectorsUsed = Math.ceil(STATE_VECTOR_SIZE / 4.0) + 25; const vectorsPerArtifact = Math.ceil(STATE_VECTOR_SIZE / 4.0) + 1; const availableVectors = maxUniformVectors - baseVectorsUsed; if (availableVectors > 0 && vectorsPerArtifact > 0) { detectedMax = Math.max(1, Math.floor((availableVectors / vectorsPerArtifact) * 0.8)); } else { detectedMax = 1; } const reasonableCap = 4; detectedMax = Math.min(detectedMax, reasonableCap, MAX_ARTIFACTS); } catch (e) { console.warn("Error detecting uniform capacity:", e); detectedMax = 1; } return detectedMax; } _createArtifactUniformArray() { return new Float32Array(MAX_ARTIFACTS_SHADER * STATE_VECTOR_SIZE).fill(0.5); } update(mainStateArray, time, currentActiveArtifactInfo, currentComplexity, currentSyncFactor, currentFeedbackIntensity) { if (!this.material || !renderer) return; this.material.uniforms.time.value = time; this.material.uniforms.complexity.value = currentComplexity; this.material.uniforms.syncFactor.value = currentSyncFactor; this.material.uniforms.feedbackIntensity.value = currentFeedbackIntensity; if (mainStateArray?.length === STATE_VECTOR_SIZE) { this.material.uniforms.mainState.value = Float32Array.from(mainStateArray); this.material.uniforms.mainState.needsUpdate = true; } const artifactStatesFlat = this.material.uniforms.artifactStates.value; const artifactSimilarities = this.material.uniforms.artifactSimilarities.value; artifactStatesFlat.fill(0.5); artifactSimilarities.fill(0.0); const numToSend = Math.min(currentActiveArtifactInfo.ids.length, MAX_ARTIFACTS_SHADER); this.material.uniforms.numActiveArtifacts.value = numToSend; for (let i = 0; i < numToSend; ++i) { const stateArr = currentActiveArtifactInfo.stateArrays[i]; const sim = currentActiveArtifactInfo.similarities[i]; if (stateArr?.length === STATE_VECTOR_SIZE) { artifactStatesFlat.set(stateArr, i * STATE_VECTOR_SIZE); artifactSimilarities[i] = sim; } else { artifactSimilarities[i] = 0.0; if(stateArr) console.warn(`Artifact data invalid size (${stateArr.length}) for shader slot ${i}`); } } this.material.uniforms.artifactStates.needsUpdate = true; this.material.uniforms.artifactSimilarities.needsUpdate = true; try { if (renderer.getContext().isContextLost()) { console.error("WebGL Context Lost! Cannot render."); showError("WebGL Context Lost!"); return; } renderer.render(scene, camera); } catch (e) { console.error("THREE.WebGLRenderer.render error:", e); if (e.message && e.message.includes("context lost")) { showError("WebGL Context Lost!"); } else { showError(`Render Error: ${e.message}`); } } } resize() { const w=window.innerWidth; const h=window.innerHeight; camera.aspect=w/h; camera.updateProjectionMatrix(); const pr=renderer.getPixelRatio(); renderer.setSize(w,h); if (this.material) this.material.uniforms.resolution.value.set(w*pr,h*pr); } }

        // --- Audio Controller ---
        class AudioController {
            constructor() {
                this.audioWorkletNode = null; this.isInitialized = false; this.isInitializing = false;
                this.micStreamSource = null; this.audioWarningDisplayed = false; this.warningTimeout = null;
                document.body.addEventListener('pointerdown', () => this.tryInitializeAudio(), { once: true, passive: true });
                document.body.addEventListener('touchstart', () => this.tryInitializeAudio(), { once: true, passive: true });
                document.addEventListener('visibilitychange', async () => { if (!audioContext) return; if (document.hidden) { if (audioContext.state === 'running') { console.log("Suspending AC due to page visibility"); await audioContext.suspend().catch(e=>console.warn("AC suspend err:", e)); } } else { await this.tryInitializeAudio(); } });
            }
            showWarning(msg, dur=5000) { const w=document.getElementById('warningInfo'); if(w){ if(this.warningTimeout) clearTimeout(this.warningTimeout); w.textContent=msg; w.style.display='block'; w.style.color='yellow'; this.audioWarningDisplayed=true; if(dur>0) this.warningTimeout=setTimeout(()=>this.hideWarning(), dur); } }
            hideWarning() { const w=document.getElementById('warningInfo'); if(w && this.audioWarningDisplayed){ w.style.display='none'; this.audioWarningDisplayed=false; if(this.warningTimeout){ clearTimeout(this.warningTimeout); this.warningTimeout=null; } } }
            async tryInitializeAudio() {
                if (this.isInitializing || (this.isInitialized && audioContext?.state === 'running')) return;
                this.isInitializing = true; interactionOccurred = true; console.log("Trying AudioContext init/resume...");
                try {
                    if (audioContext && audioContext.state !== 'running') { console.log(`Closing previous AudioContext (state: ${audioContext.state})`); await audioContext.close().catch(e => console.error("AudioContext close error:", e)); audioContext=null; this.audioWorkletNode=null; this.isInitialized=false; this.micStreamSource=null; analyserNode=null; masterGain=null; currentInputState.mic.available=false; }
                    if (!audioContext) { audioContext = new (window.AudioContext || window.webkitAudioContext)({ latencyHint: 'interactive', sampleRate: 44100 }); console.log(`AudioContext created. State: ${audioContext.state}, Sample Rate: ${audioContext.sampleRate}`); masterGain = audioContext.createGain(); masterGain.gain.setValueAtTime(1.0, audioContext.currentTime); masterGain.connect(audioContext.destination); analyserNode = audioContext.createAnalyser(); analyserNode.fftSize = MIC_FFT_SIZE; analyserNode.smoothingTimeConstant = 0.5; currentInputState.mic.fft = new Float32Array(analyserNode.frequencyBinCount); }
                    if (audioContext.state === 'suspended') { console.log("AudioContext suspended, resuming..."); await audioContext.resume(); console.log(`AudioContext resumed. State: ${audioContext.state}`); }
                } catch (e) { console.error("AudioContext create/resume failed:", e); showError("Audio Error: Context init failed."); this.isInitializing = false; return; }

                if (audioContext.state === 'running' && !this.isInitialized) {
                    console.log("Adding AudioWorklet for PsySynth...");
                    if (!audioContext.audioWorklet) { console.error("!!! AudioContext.audioWorklet is undefined."); showError("Audio Error: Worklet API not available."); this.isInitializing = false; this.isInitialized = false; return; }
                    try {
                        const processorCode = `
                            const WORKLET_STATE_SIZE = ${STATE_VECTOR_SIZE};
                            function fract(n){return n-Math.floor(n);} function lerp(a,b,t){return a+(b-a)*t;} function clamp(v,min,max){return Math.min(max,Math.max(min,v));} function hash(n){return fract(Math.sin(n*12.9898)*43758.5);} function softClip(x, k = 1.0) { return Math.tanh(x * k); } function mtof(m) { return 440.0 * Math.pow(2.0, (m - 69.0) / 12.0); }
                            class SVF{ constructor(){this.z1=0;this.z2=0;this.g=0;this.k=0;this.inv_den=0;this.type='lp';} setParams(cutoffNorm,resNorm,sampleRate,type='lp'){ const f=20*Math.pow(1000,clamp(cutoffNorm,.001,.999)); const q=0.5+clamp(resNorm,0,.98)*19.5; this.g=Math.tan(Math.PI*f/sampleRate); this.k=1/q; const g2=this.g*this.g; this.inv_den=1/(1+this.k*this.g+g2); this.type=type; } process(input){ const v0=input; const v1=(this.z1+this.g*(v0-this.z2))*this.inv_den; const v2=(this.z2+this.g*v1)*this.inv_den; this.z1=2*v1-this.z1; this.z2=2*v2-this.z2; if(this.type==='lp') return v2; if(this.type==='bp') return v1; if(this.type==='hp') return v0-this.k*v1-v2; if(this.type==='notch') return v0-this.k*v1; return v2; } }
                            class Envelope { constructor(sr) { this.sr = sr; this.level = 0; this.phase = 'off'; this.attack=0.01;this.decay=0.1;this.sustain=0.5;this.release=0.2;} trigger(attackS, decayS, sustainLvl, releaseS) { this.attack = Math.max(0.001, attackS); this.decay = Math.max(0.001, decayS); this.sustain = clamp(sustainLvl,0,1); this.release = Math.max(0.001, releaseS); this.phase = 'attack'; this.level = 0; } noteOff() { if(this.phase !== 'off') this.phase = 'release'; } process() { const srInv = 1.0 / this.sr; switch (this.phase) { case 'attack': this.level += srInv / this.attack; if (this.level >= 1) { this.level = 1; this.phase = 'decay'; } break; case 'decay': this.level -= (1 - this.sustain) * srInv / this.decay; if (this.level <= this.sustain) { this.level = this.sustain; this.phase = 'sustain'; } break; case 'sustain': break; case 'release': this.level -= this.level * srInv / this.release; if (this.level <= 0.0001) { this.level = 0; this.phase = 'off'; } break; case 'off': this.level = 0; break; } return this.level = clamp(this.level,0,1); } isActive() { return this.phase !== 'off';} }
                            class GenerativeProcessor extends AudioWorkletProcessor {
                                constructor(options) { super(options); this.sr=sampleRate; this.phase=0; this.state=new Array(WORKLET_STATE_SIZE).fill(.5); this.lastBeatPhase=0; this.lastSixteenthPhase=0; this.beatCounter=0; this.sixteenthCounter=0; this.complexity=0.5; this.menuParams={}; this.lfoPhase={leadPitch:0, noiseFx:0, bassFilter:0, leadFilter:0}; this.kickEnv=new Envelope(this.sr); this.bassFEnv=new Envelope(this.sr); this.bassAEnv=new Envelope(this.sr); this.leadFEnv=new Envelope(this.sr); this.leadAEnv=new Envelope(this.sr); this.snareNoiseEnv=new Envelope(this.sr); this.snareBodyEnv=new Envelope(this.sr); this.filters={ bassL:new SVF(),bassR:new SVF(),leadL:new SVF(),leadR:new SVF(),hatL:new SVF(),hatR:new SVF(),snareNoiseL:new SVF(),snareNoiseR:new SVF(),snareBodyL:new SVF(),snareBodyR:new SVF(),noiseFxL:new SVF(),noiseFxR:new SVF() }; const maxDelaySeconds=1.2; this.delayBuffer=[new Float32Array(Math.ceil(this.sr*maxDelaySeconds)), new Float32Array(Math.ceil(this.sr*maxDelaySeconds))]; this.delayWritePos=[0,0]; const combDelaysSeconds=[.0311,.0383,.0427,.0459]; const createCombBuf=s=>new Float32Array(Math.ceil(this.sr*s)); this.combBuffers=combDelaysSeconds.map(l=>[createCombBuf(l),createCombBuf(l)]); this.combWritePos=combDelaysSeconds.map(()=>[0,0]); this.combLastSample=combDelaysSeconds.map(()=>[0,0]); const apDelaysSeconds=[.0053,.0121]; const createAPBuf=s=>new Float32Array(Math.ceil(this.sr*s)); this.apBuffers=apDelaysSeconds.map(l=>[createAPBuf(l),createAPBuf(l)]); this.apWritePos=apDelaysSeconds.map(()=>[0,0]); this.port.onmessage=(e)=>{ if(e.data.state?.length===WORKLET_STATE_SIZE)this.state=e.data.state; if(typeof e.data.complexity==='number')this.complexity=clamp(e.data.complexity,0,1); if(e.data.menuParams)this.menuParams=e.data.menuParams;}; console.log("PsySynth Worklet Initialized. SR:", this.sr); }
                                static get parameterDescriptors(){ return[{name:'masterLevel',defaultValue:0.7,minValue:0,maxValue:1.0,automationRate:'a-rate'}];} 
                                getStateVal(idx,defVal=0.5){return(this.state&&this.state[idx]!==undefined)?this.state[idx]:defVal;}
                                getMenuParam(key,defVal=0.5){return(this.menuParams&&this.menuParams[key]!==undefined)?this.menuParams[key]:defVal;}
                                process(inputs,outputs,parameters){
                                    const output=outputs[0]; const bufferSize=output[0].length; const masterLevelParam=parameters.masterLevel; const srInv=1.0/this.sr; const comp=this.complexity; const bpm=this.getMenuParam('masterBPM',140); const secondsPerBeat=60.0/clamp(bpm,40,260);
                                    const hnmKickMod=this.getStateVal(0); const hnmBassCutMod=this.getStateVal(2); const hnmBassResMod=this.getStateVal(3); const hnmLeadCutMod=this.getStateVal(6); const hnmLeadResMod=this.getStateVal(7); const hnmLeadPitchLfoRateMod=this.getStateVal(21); const hnmLeadPitchLfoDepthMod=this.getStateVal(18); const hnmHatTimeMod=this.getStateVal(28); const hnmSnareToneMod=this.getStateVal(38); const hnmNoiseCutMod=this.getStateVal(13); const hnmDelayTimeMod = this.getStateVal(31); const hnmReverbMixMod = this.getStateVal(10);
                                    const kickBasePitch = 30 + this.getMenuParam('kickTune',0.5)*40; const kickPitchEnvAmt = 500 + this.getMenuParam('kickPunch',0.7)*1500; const kickPitchDecay = 0.005 + this.getMenuParam('kickPunch',0.7)*0.03; const kickAmpDecay = 0.05 + this.getMenuParam('kickDecay',0.2)*0.25; const kickClick = this.getMenuParam('kickClick',0.5); const kickLevel = this.getMenuParam('kickLevel',0.8);
                                    const bassOscType = this.getMenuParam('bassOscType',0); const bassOct = Math.floor(this.getMenuParam('bassOctave',0.3)*3)-1; const bassBaseFreq = mtof(36 + bassOct*12); const bassCut = clamp(this.getMenuParam('bassCutoff',0.3) + (hnmBassCutMod-0.5)*0.2, 0.01, 0.95); const bassRes = clamp(this.getMenuParam('bassReso',0.6) + (hnmBassResMod-0.5)*0.3, 0.0, 0.95); const bassFEnvAmt = this.getMenuParam('bassEnvAmt',0.7); const bassFDecay = 0.01 + this.getMenuParam('bassFilterDecay',0.15)*0.2; const bassADecay = 0.01 + this.getMenuParam('bassAmpDecay',0.1)*0.3; const bassFilterLfoRateVal = this.getMenuParam('bassFilterLfoRate', 0.2) * 10; const bassFilterLfoDepthVal = this.getMenuParam('bassFilterLfoDepth', 0.3); const bassLevel = this.getMenuParam('bassLevel',0.7);
                                    const leadOscType = this.getMenuParam('leadOscType',0); const leadOct = Math.floor(this.getMenuParam('leadOctave',0.6)*3)-1; const leadBaseFreq = mtof(60 + leadOct*12); const leadPW = this.getMenuParam('leadPW',0.5); const leadCut = clamp(this.getMenuParam('leadCutoff',0.6) + (hnmLeadCutMod-0.5)*0.3, 0.01, 0.95); const leadRes = clamp(this.getMenuParam('leadReso',0.7) + (hnmLeadResMod-0.5)*0.3, 0.0, 0.95); const leadFEnvAmt = this.getMenuParam('leadEnvAmt',0.8); const leadFDecay = 0.01 + this.getMenuParam('leadFilterDecay',0.3)*0.5; const leadADecay = 0.01 + this.getMenuParam('leadAmpDecay',0.4)*0.8; const leadPitchLfoRate = (1 + this.getMenuParam('leadPitchLfoRate',0.5)*19) * (0.5 + (hnmLeadPitchLfoRateMod-0.5)*1.5); const leadPitchLfoDepth = this.getMenuParam('leadPitchLfoDepth',0.3)*12 * (0.5 + (hnmLeadPitchLfoDepthMod-0.5)*1.5); const leadFilterLfoRateVal = this.getMenuParam('leadFilterLfoRate', 0.3) * 15; const leadFilterLfoDepthVal = this.getMenuParam('leadFilterLfoDepth', 0.4); const leadLevel = this.getMenuParam('leadLevel',0.6);
                                    const hatClosedDecay = 0.005 + this.getMenuParam('hatClosedDecay',0.05)*0.05 * (0.5 + (hnmHatTimeMod-0.5)*0.8); const hatOpenDecay = 0.05 + this.getMenuParam('hatOpenDecay',0.25)*0.2 * (0.5 + (hnmHatTimeMod-0.5)*0.8); const baseHatHpfCut = this.getMenuParam('hatHpfCutoff',0.7); const hatToneVal = this.getMenuParam('hatTone', 0.5); const finalHatHpfCut = clamp(baseHatHpfCut + (hatToneVal - 0.5) * 0.3, 0.1, 0.95); const hatLevel = this.getMenuParam('hatLevel',0.5);
                                    const snareNoiseDecay = 0.01 + this.getMenuParam('snareNoiseDecay',0.08)*0.1; const snareNoiseLevelVal = this.getMenuParam('snareNoiseLevel',0.8); const snareBodyTune = 40 + this.getMenuParam('snareBodyTune',0.5)*160 * (0.8 + (hnmSnareToneMod-0.5)*0.4) ; const snareBodyDecay = 0.02 + this.getMenuParam('snareBodyDecay',0.15)*0.2; const snareBodyLevelVal = this.getMenuParam('snareBodyLevel', 0.5); const snareMasterLevel = this.getMenuParam('snareLevel',0.6);
                                    const noiseFxFiltTypeVal = this.getMenuParam('noiseFxFiltType',0); const noiseFxCut = clamp(this.getMenuParam('noiseFxCutoff',0.5) + (hnmNoiseCutMod-0.5)*0.4, 0.01,0.95); const noiseFxRes = this.getMenuParam('noiseFxReso',0.4); const noiseFxLfoRate = 0.1 + this.getMenuParam('noiseFxLfoRate',0.3)*5; const noiseFxLfoDepth = this.getMenuParam('noiseFxLfoDepth',0.6); const noiseFxLevel = this.getMenuParam('noiseFxLevel',0.4); 
                                    const delayTimeModeVal = this.getMenuParam('delayTimeMode',2); let delayTimeSec = secondsPerBeat*3/8; const delayTimeModFactor = 0.5 + (hnmDelayTimeMod-0.5)*0.9; if(delayTimeModeVal === 0) delayTimeSec = secondsPerBeat/4; else if(delayTimeModeVal === 1) delayTimeSec = secondsPerBeat/2; else if(delayTimeModeVal === 2) delayTimeSec = secondsPerBeat*3/8; else if(delayTimeModeVal === 3) delayTimeSec = secondsPerBeat; else if(delayTimeModeVal === 4) delayTimeSec = secondsPerBeat*2; delayTimeSec = Math.max(0.001, delayTimeSec * delayTimeModFactor);
                                    const delayFeedback = this.getMenuParam('delayFeedback',0.45); const delayMix = this.getMenuParam('delayMix',0.3);
                                    const reverbSize = this.getMenuParam('reverbSize',0.7); const reverbDamp = this.getMenuParam('reverbDamp',0.5); const reverbMix = this.getMenuParam('reverbMix',0.25) * (0.5 + (hnmReverbMixMod-0.5)*1.8);
                                    const lfoUpdateVal = bufferSize * srInv; this.lfoPhase.leadPitch = fract(this.lfoPhase.leadPitch + lfoUpdateVal * leadPitchLfoRate); this.lfoPhase.noiseFx = fract(this.lfoPhase.noiseFx + lfoUpdateVal * noiseFxLfoRate); this.lfoPhase.bassFilter = fract(this.lfoPhase.bassFilter + lfoUpdateVal * bassFilterLfoRateVal); this.lfoPhase.leadFilter = fract(this.lfoPhase.leadFilter + lfoUpdateVal * leadFilterLfoRateVal);
                                    const bassFilterLfoMod = Math.sin(this.lfoPhase.bassFilter * 2 * Math.PI) * bassFilterLfoDepthVal; this.filters.bassL.setParams(clamp(bassCut+bassFilterLfoMod,0.01,0.95),bassRes,this.sr,'lp'); this.filters.bassR.setParams(clamp(bassCut+bassFilterLfoMod,0.01,0.95),bassRes,this.sr,'lp'); 
                                    const leadFilterLfoMod = Math.sin(this.lfoPhase.leadFilter * 2 * Math.PI) * leadFilterLfoDepthVal; this.filters.leadL.setParams(clamp(leadCut+leadFilterLfoMod,0.01,0.95),leadRes,this.sr,'lp'); this.filters.leadR.setParams(clamp(leadCut+leadFilterLfoMod,0.01,0.95),leadRes,this.sr,'lp'); 
                                    this.filters.hatL.setParams(finalHatHpfCut,0.1,this.sr,'hp'); this.filters.hatR.setParams(finalHatHpfCut,0.1,this.sr,'hp'); this.filters.snareNoiseL.setParams(0.3,0.2,this.sr,'hp');this.filters.snareNoiseR.setParams(0.3,0.2,this.sr,'hp'); this.filters.snareBodyL.setParams(clamp(snareBodyTune/1000,0.05,0.8),0.5,this.sr,'bp');this.filters.snareBodyR.setParams(clamp(snareBodyTune/1000,0.05,0.8),0.5,this.sr,'bp'); const noiseFxFiltType = noiseFxFiltTypeVal < 0.33 ? 'lp' : (noiseFxFiltTypeVal < 0.66 ? 'hp' : 'bp'); this.filters.noiseFxL.setParams(clamp(noiseFxCut + Math.sin(this.lfoPhase.noiseFx*2*Math.PI)*noiseFxLfoDepth*0.5,0.01,0.95),noiseFxRes,this.sr,noiseFxFiltType); this.filters.noiseFxR.setParams(clamp(noiseFxCut + Math.cos(this.lfoPhase.noiseFx*2*Math.PI)*noiseFxLfoDepth*0.5,0.01,0.95),noiseFxRes,this.sr,noiseFxFiltType);

                                    for(let ch=0;ch<output.length;++ch){ const outCh=output[ch];
                                        for(let i=0;i<bufferSize;++i){
                                            const currentMasterLevel = masterLevelParam.length>1?masterLevelParam[i]:masterLevelParam[0]; const currentPhase=this.phase+i; const currentTime=currentPhase*srInv; const currentBeat=currentTime/secondsPerBeat; const beatPhase=fract(currentBeat); const sixteenthPhase=fract(currentBeat*4.0); const sixteenthNum=Math.floor(currentBeat*4.0); const beatTrig=beatPhase<this.lastBeatPhase; const sixteenthTrig=sixteenthPhase<this.lastSixteenthPhase; if(beatTrig)this.beatCounter=(this.beatCounter+1)%4; if(sixteenthTrig)this.sixteenthCounter=(this.sixteenthCounter+1)%16; this.lastBeatPhase=beatPhase;this.lastSixteenthPhase=sixteenthPhase;
                                            let kickSig=0; if(beatTrig && this.beatCounter===0){ this.kickEnv.trigger(0.002,kickAmpDecay,0,kickAmpDecay); } const kickEnvVal=this.kickEnv.process(); if(kickEnvVal>0){ const pitch=kickBasePitch+kickPitchEnvAmt*Math.exp(-this.kickEnv.level/kickPitchDecay); kickSig=Math.sin(currentTime*2*Math.PI*pitch)*kickEnvVal; kickSig+=(hash(currentTime*9000+ch)-.5)*kickClick*kickEnvVal*Math.exp(-this.kickEnv.level/0.002); }
                                            let bassSig=0; const playBass=this.getStateVal(4,0) < 0.5 ? (sixteenthTrig && (this.sixteenthCounter%2 !==0)) : (sixteenthTrig && [0,3,6,7,9,12,14,15].includes(this.sixteenthCounter)); if(playBass){ this.bassAEnv.trigger(0.005,bassADecay,0,bassADecay); this.bassFEnv.trigger(0.005,bassFDecay,0,bassFDecay);} const bassAEnvVal=this.bassAEnv.process(); const bassFEnvVal=this.bassFEnv.process(); if(bassAEnvVal>0){ let rawBass=0; const freq=bassBaseFreq*(1.0+(this.getStateVal(20,0.5)-0.5)*0.05); if(bassOscType<0.5) rawBass=(fract(currentTime*freq)*2-1); else rawBass=fract(currentTime*freq)<leadPW?1:-1; rawBass*=bassAEnvVal; const filt = ch===0?this.filters.bassL:this.filters.bassR; filt.setParams(clamp(bassCut+bassFEnvVal*bassFEnvAmt + bassFilterLfoMod,0.01,0.95),bassRes,this.sr,'lp'); bassSig=filt.process(rawBass); }
                                            let leadSig=0; const playLead = this.getStateVal(19,0) < 0.5 ? (sixteenthTrig && [0,4,7,10,13].includes(this.sixteenthCounter)) : (sixteenthTrig && (this.sixteenthCounter%3===0 || this.sixteenthCounter%5===0)); if(playLead){ this.leadAEnv.trigger(0.005,leadADecay,0,leadADecay); this.leadFEnv.trigger(0.005,leadFDecay,0,leadFDecay); } const leadAEnvVal=this.leadAEnv.process(); const leadFEnvVal=this.leadFEnv.process(); if(leadAEnvVal>0){ let rawLead=0; const pitchLfo = Math.sin(this.lfoPhase.leadPitch * 2 * Math.PI) * leadPitchLfoDepth; const freq = leadBaseFreq * Math.pow(2, pitchLfo/12); if(leadOscType<0.33) rawLead = (fract(currentTime*freq)*2-1); else if(leadOscType<0.66) rawLead = fract(currentTime*freq)<leadPW?1:-1; else rawLead = Math.sin(currentTime*2*Math.PI*freq + Math.sin(currentTime*2*Math.PI*freq*6)*0.3); rawLead*=leadAEnvVal; const filt=ch===0?this.filters.leadL:this.filters.leadR; filt.setParams(clamp(leadCut+leadFEnvVal*leadFEnvAmt + leadFilterLfoMod,0.01,0.95),leadRes,this.sr,'lp'); leadSig=filt.process(rawLead); }
                                            let hatSig=0; const playHatClosed=sixteenthTrig && this.sixteenthCounter%2 !==0; const playHatOpen=sixteenthTrig && this.sixteenthCounter%4===2; if(playHatClosed) hatSig+=(hash(currentTime*15000+ch)-.5)*Math.exp(-sixteenthPhase/hatClosedDecay); if(playHatOpen) hatSig+=(hash(currentTime*18000+ch)-.5)*Math.exp(-sixteenthPhase/hatOpenDecay); const hatFilt=ch===0?this.filters.hatL:this.filters.hatR; hatSig=hatFilt.process(hatSig);
                                            let snareSigPartNoise=0; let snareSigPartBody=0; if(beatTrig && (this.beatCounter===1 || this.beatCounter===3)){ this.snareNoiseEnv.trigger(0.001,snareNoiseDecay,0,snareNoiseDecay); this.snareBodyEnv.trigger(0.002,snareBodyDecay,0,snareBodyDecay); } const snareNEnvVal=this.snareNoiseEnv.process(); const snareBEnvVal=this.snareBodyEnv.process(); if(snareNEnvVal>0){ const noiseFilt=ch===0?this.filters.snareNoiseL:this.filters.snareNoiseR; snareSigPartNoise = noiseFilt.process((hash(currentTime*20000+ch)-.5)*snareNEnvVal) * snareNoiseLevelVal; } if(snareBEnvVal>0){ const bodyFilt=ch===0?this.filters.snareBodyL:this.filters.snareBodyR; snareSigPartBody = bodyFilt.process(Math.sin(currentTime*2*Math.PI*snareBodyTune)*snareBEnvVal) * snareBodyLevelVal; } const snareSig = (snareSigPartNoise + snareSigPartBody) * snareMasterLevel;
                                            let noiseFxSig=(hash(currentTime*1000+ch)-.5); const noiseFiltFx=ch===0?this.filters.noiseFxL:this.filters.noiseFxR; noiseFxSig=noiseFiltFx.process(noiseFxSig);
                                            let dryMix = kickSig*kickLevel + bassSig*bassLevel + leadSig*leadLevel + hatSig*hatLevel + snareSig + noiseFxSig*noiseFxLevel; dryMix = softClip(dryMix*0.7); // snareSig already includes master level
                                            let dwp=this.delayWritePos[ch]; const delayBuf=this.delayBuffer[ch]; const delayLen=delayBuf.length; const delayReadPos=(dwp - Math.floor(delayTimeSec*this.sr) + delayLen)%delayLen; const delayedSample=delayBuf[delayReadPos]; delayBuf[dwp]=softClip(dryMix + delayedSample*delayFeedback);
                                            let combSum=0; for(let c=0;c<this.combBuffers.length;c++){const cBuf=this.combBuffers[c][ch];const cLen=cBuf.length;const cReadPos=(this.combWritePos[c][ch]-cLen+cLen)%cLen;let cOut=cBuf[cReadPos];this.combLastSample[c][ch]=cOut*(1.0-reverbDamp*0.5)+this.combLastSample[c][ch]*reverbDamp*0.5; cBuf[this.combWritePos[c][ch]]=softClip(dryMix+this.combLastSample[c][ch]*reverbSize*0.95);combSum+=cOut;this.combWritePos[c][ch]=(this.combWritePos[c][ch]+1)%cLen;} combSum*=1.0/this.combBuffers.length;
                                            let apInput=combSum;let apOut=0; for(let a=0;a<this.apBuffers.length;a++){const aBuf=this.apBuffers[a][ch];const aLen=aBuf.length;const aReadPos=(this.apWritePos[a][ch]-aLen+aLen)%aLen;apOut=aBuf[aReadPos];const apProc=softClip(apInput+apOut*0.5);aBuf[this.apWritePos[a][ch]]=apProc;apInput=apOut-apProc*0.5;this.apWritePos[a][ch]=(this.apWritePos[a][ch]+1)%aLen;}
                                            const wetSignal=apInput;
                                            outCh[i]=softClip((dryMix*(1.0-delayMix-reverbMix) + delayedSample*delayMix + wetSignal*reverbMix) * currentMasterLevel * 0.8);
                                            this.delayWritePos[ch]=(dwp+1)%delayLen;
                                        }
                                    }
                                    this.phase+=bufferSize; return true;
                                }
                            }
                            registerProcessor('generative-processor', GenerativeProcessor);
                        `;
                        const blob = new Blob([processorCode], { type: 'application/javascript' }); const workletURL = URL.createObjectURL(blob);
                        await audioContext.audioWorklet.addModule(workletURL); console.log("PsySynth AudioWorklet module added.");
                        this.audioWorkletNode = new AudioWorkletNode(audioContext, 'generative-processor', { outputChannelCount:[2], parameterData:{ masterLevel: 0.7 } }); 
                        this.audioWorkletNode.connect(masterGain); console.log("PsySynth AudioWorklet Node connected."); URL.revokeObjectURL(workletURL);
                        this.isInitialized = true; this.hideWarning(); await this.setupMicrophone();
                    } catch (err) { console.error("!!! PsySynth AudioWorklet Init Failed:", err); if(err.message && err.message.includes("SyntaxError")) { showError("Audio Error: Engine syntax error. Check console."); } else { showError("Audio Error: Worklet setup failed."); } this.isInitialized=false; this.audioWorkletNode?.disconnect(); this.audioWorkletNode=null; this.micStreamSource?.disconnect(); this.micStreamSource=null; currentInputState.mic.available=false; }
                } else if (audioContext.state === 'running' && this.isInitialized) { await this.setupMicrophone(); }
                this.isInitializing = false;
            }
            update(hnmStateTensor, complexityValue, currentMenuParams) { 
                if (!this.isInitialized || !this.audioWorkletNode || !hnmStateTensor || hnmStateTensor.isDisposed) return;
                if (this.audioWorkletNode.port) {
                    hnmStateTensor.squeeze([0,1]).data().then(hnmStateArray => {
                        if(hnmStateArray.length === STATE_VECTOR_SIZE) {
                           if (this.audioWorkletNode?.port) {
                               const sanitizedMenuParams = {};
                               for (const key in currentMenuParams) {
                                   if (typeof currentMenuParams[key] !== 'function') {
                                       sanitizedMenuParams[key] = currentMenuParams[key];
                                   }
                               }
                               this.audioWorkletNode.port.postMessage({ state: hnmStateArray, complexity: complexityValue, menuParams: sanitizedMenuParams });
                           }
                        } else { console.warn(`HNM State array size mismatch for worklet: got ${hnmStateArray.length}`); }
                    }).catch(e => console.error("Error getting HNM tensor data for audio:", e));
                }
                const masterLevelParam = this.audioWorkletNode.parameters?.get('masterLevel');
                if(masterLevelParam && audioContext?.currentTime !== undefined) {
                    const hnmMasterVolModIndex = 15; 
                     hnmStateTensor.slice([0, 0, hnmMasterVolModIndex], [1, 1, 1]).squeeze([0,1]).data().then(data => {
                        const hnmMod = (data[0] !== undefined ? data[0] : 0.5) * 0.4 + 0.3; 
                        const targetLevel = clamp(hnmMod , 0.0, 1.0); 
                        masterLevelParam.linearRampToValueAtTime(targetLevel, audioContext.currentTime + 0.05);
                    }).catch(e => console.error("Error reading HNM gain state for audio param:", e));
                }
            }
            getMicrophoneInput() { if(!this.isInitialized || !analyserNode || !currentInputState.mic.fft || audioContext?.state !=='running' || !currentInputState.mic.available){ currentInputState.mic.fft.fill(-140); return{level:0, fft:currentInputState.mic.fft, available:false, rhythmPeak:0, rhythmTempo:0}; } analyserNode.getFloatFrequencyData(currentInputState.mic.fft); let sumSquares = 0; let count = 0; const len = analyserNode.frequencyBinCount; for(let i=0; i<len; i++){ const dB = currentInputState.mic.fft[i]; if(isFinite(dB) && dB > -100){ sumSquares += Math.pow(10, dB / 10); count++; } else { currentInputState.mic.fft[i] = -140; } } let rmsPower = count > 0 ? sumSquares / count : 0; currentInputState.mic.level = clamp(Math.sqrt(rmsPower) * 11.0, 0, 1); const micRhythm = analyzeRhythm(currentInputState.mic.fft, audioContext.sampleRate, MIC_FFT_SIZE); currentInputState.mic.rhythmPeak = micRhythm.peak; currentInputState.mic.rhythmTempo = micRhythm.tempo; return { level: currentInputState.mic.level, fft: currentInputState.mic.fft, available: true, rhythmPeak: micRhythm.peak, rhythmTempo: micRhythm.tempo }; }
            async setupMicrophone() { if(this.micStreamSource || !this.isInitialized || !audioContext || audioContext.state !== 'running' || !analyserNode){ return; } console.log("Requesting microphone access..."); try{ const stream = await navigator.mediaDevices.getUserMedia({ audio:{ echoCancellation: false, noiseSuppression: false, autoGainControl: false }, video:false }); this.micStreamSource = audioContext.createMediaStreamSource(stream); this.micStreamSource.connect(analyserNode); console.log("Microphone connected to analyser."); currentInputState.mic.available = true; if(currentInputState.mic.fft.length !== analyserNode.frequencyBinCount){ currentInputState.mic.fft = new Float32Array(analyserNode.frequencyBinCount); console.log("Mic FFT buffer resized to:", analyserNode.frequencyBinCount); } speechController?.requestPermissionAndInit(); } catch(err){ console.error("Microphone access denied or failed:", err); showWarning("Mic Disabled/Denied.", 5000); currentInputState.mic.available = false; currentInputState.mic.fft.fill(-140); speechController?.requestPermissionAndInit(); } }
        }

        function requestFullscreen() { const elem = document.documentElement; if (elem.requestFullscreen) { elem.requestFullscreen().catch(err => console.warn(`Fullscreen request failed: ${err.message}`)); } else if (elem.webkitRequestFullscreen) { elem.webkitRequestFullscreen().catch(err => console.warn(`Fullscreen request failed (webkit): ${err.message}`)); } else if (elem.msRequestFullscreen) { elem.msRequestFullscreen().catch(err => console.warn(`Fullscreen request failed (ms): ${err.message}`)); } else { console.warn("Fullscreen API not supported on this browser."); } }
        function setupInputListeners() {
            const canvas = document.getElementById('renderCanvas'); const resetButton = document.getElementById('resetButton');
            const handlePointerMove = (e) => { const x = clamp(e.clientX / window.innerWidth, 0, 1); const y = 1.0 - clamp(e.clientY / window.innerHeight, 0, 1); currentInputState.touch.dx = x - currentInputState.touch.lastX; currentInputState.touch.dy = y - currentInputState.touch.lastY; currentInputState.touch.x = x; currentInputState.touch.y = y; currentInputState.touch.lastX = x; currentInputState.touch.lastY = y; currentInputState.touch.pressure = (e.pressure !== undefined && e.pointerType === 'touch') ? e.pressure : (currentInputState.touch.active ? 1.0 : 0); if (currentInputState.touch.active) { e.preventDefault(); } };
            const handlePointerDown = (e) => { e.preventDefault(); const now = performance.now(); if (!interactionOccurred) { audioController?.tryInitializeAudio(); requestMotionPermission(); requestAccelerometerPermission(); const fullscreenAlreadyRequested = sessionStorage.getItem(FULLSCREEN_REQUESTED_KEY); if (!fullscreenAlreadyRequested) { console.log("Requesting fullscreen on first interaction."); requestFullscreen(); sessionStorage.setItem(FULLSCREEN_REQUESTED_KEY, 'true'); } interactionOccurred = true; } if (menuSettings.enableTapReset && resetGestureState.longPressDetected && (now - resetGestureState.longPressReleaseTime < RESET_SECOND_TAP_WINDOW_MS)) { console.log("Reset Gesture Confirmed!"); showWarning("Resetting State...", 1500); resetButton.click(); if (resetGestureState.resetTimeout) clearTimeout(resetGestureState.resetTimeout); resetGestureState.longPressDetected = false; resetGestureState.pointerDownTime = 0; resetGestureState.longPressReleaseTime = 0; return; } currentInputState.touch.active = true; currentInputState.touch.dx = 0; currentInputState.touch.dy = 0; currentInputState.touch.lastX = clamp(e.clientX / window.innerWidth, 0, 1); currentInputState.touch.lastY = 1.0 - clamp(e.clientY / window.innerHeight, 0, 1); currentInputState.touch.x = currentInputState.touch.lastX; currentInputState.touch.y = currentInputState.touch.lastY; handlePointerMove(e); if (speechController && menuSettings.enableSpeechCommands && speechController.permissionGranted && !speechController.isListening && !speechController.isActive && !speechController.isStarting) { speechController.startListening(); } resetGestureState.pointerDownTime = now; resetGestureState.longPressDetected = false; resetGestureState.longPressReleaseTime = 0; if (resetGestureState.resetTimeout) clearTimeout(resetGestureState.resetTimeout); };
            const handlePointerUp = (e) => { e.preventDefault(); const now = performance.now(); if (currentInputState.touch.active) { if (menuSettings.enableTapReset) { const pressDuration = now - resetGestureState.pointerDownTime; if (pressDuration > LONG_PRESS_DURATION_MS && resetGestureState.pointerDownTime > 0) { console.log("Long press detected. Waiting for second tap..."); showWarning(`Long Press: Tap again within ${RESET_SECOND_TAP_WINDOW_MS}ms to Reset.`, RESET_SECOND_TAP_WINDOW_MS + 100); resetGestureState.longPressDetected = true; resetGestureState.longPressReleaseTime = now; if (resetGestureState.resetTimeout) clearTimeout(resetGestureState.resetTimeout); resetGestureState.resetTimeout = setTimeout(() => { if (resetGestureState.longPressDetected) { console.log("Reset gesture second tap window expired."); resetGestureState.longPressDetected = false; resetGestureState.longPressReleaseTime = 0; hideWarning(); } }, RESET_SECOND_TAP_WINDOW_MS); } else { resetGestureState.longPressDetected = false; resetGestureState.longPressReleaseTime = 0; if (resetGestureState.resetTimeout) clearTimeout(resetGestureState.resetTimeout); const warnDiv = document.getElementById('warningInfo'); if(warnDiv && warnDiv.style.display !== 'none' && warnDiv.textContent.includes("Tap again")) hideWarning(); } } else { resetGestureState.longPressDetected = false; resetGestureState.longPressReleaseTime = 0; if (resetGestureState.resetTimeout) clearTimeout(resetGestureState.resetTimeout); } currentInputState.touch.active = false; currentInputState.touch.pressure = 0; currentInputState.touch.dx = 0; currentInputState.touch.dy = 0; resetGestureState.pointerDownTime = 0; } };
            canvas.addEventListener('pointerdown', handlePointerDown, { passive: false }); canvas.addEventListener('pointerup', handlePointerUp, { passive: false }); canvas.addEventListener('pointerleave', handlePointerUp, { passive: false }); canvas.addEventListener('pointermove', handlePointerMove, { passive: false });
            resetButton.addEventListener('click', () => { console.log("Resetting HNM/RAG state via button click (programmatic)..."); speechController?.stopListening(); try { sessionStorage.setItem('hnm_rag_reset_just_occurred', 'true'); localStorage.removeItem(LOCAL_STORAGE_KEY); sessionStorage.removeItem(FULLSCREEN_REQUESTED_KEY); console.log(`Cleared HNM/RAG localStorage for key: ${LOCAL_STORAGE_KEY}. Menu settings preserved.`); showWarning("HNM/RAG State Cleared. Reloading...", 1500); setTimeout(() => { window.location.reload(); }, 500); } catch (e) { console.error("Error clearing HNM/RAG storage:", e); showError("Failed to clear HNM/RAG state."); } });
            let motionListenerAdded = false; const requestMotionPermission = () => { if(motionListenerAdded) return; const addListener = () => { window.addEventListener('deviceorientation', handleOrientation, true); motionListenerAdded = true; console.log("DeviceOrientation listener added."); }; if (typeof DeviceOrientationEvent !== 'undefined' && typeof DeviceOrientationEvent.requestPermission === 'function') { DeviceOrientationEvent.requestPermission().then(state => { if (state === 'granted') { addListener(); } else { console.warn("DeviceOrientation permission denied."); currentInputState.motion.available = false; } }).catch(e => { console.error("DeviceOrientation permission request error:", e); currentInputState.motion.available = false; }); } else { addListener(); } };
            const handleOrientation = (e) => { if (e.alpha !== null || e.beta !== null || e.gamma !== null) { currentInputState.motion.alpha = e.alpha || 0; currentInputState.motion.beta = e.beta || 0; currentInputState.motion.gamma = e.gamma || 0; if (!currentInputState.motion.available) { console.log("DeviceOrientation data received."); currentInputState.motion.available = true; } } };
            let accelListenerAdded = false; const requestAccelerometerPermission = () => { if (accelListenerAdded) return; const addListener = () => { window.addEventListener('devicemotion', handleMotion, true); accelListenerAdded = true; console.log("DeviceMotion (Accelerometer) listener added."); }; if (typeof DeviceMotionEvent !== 'undefined' && typeof DeviceMotionEvent.requestPermission === 'function') { DeviceMotionEvent.requestPermission().then(state => { if (state === 'granted') { addListener(); } else { console.warn("DeviceMotion permission denied."); currentInputState.accelerometer.available = false; } }).catch(e => { console.error("DeviceMotion permission request error:", e); currentInputState.accelerometer.available = false; }); } else { addListener(); } };
            const handleMotion = (event) => { const acc = event.accelerationIncludingGravity; if (acc && (acc.x != null || acc.y != null || acc.z != null)) { currentInputState.accelerometer.x = acc.x || 0; currentInputState.accelerometer.y = acc.y || 0; currentInputState.accelerometer.z = acc.z || 0; const magnitude = Math.sqrt((acc.x || 0)**2 + (acc.y || 0)**2 + (acc.z || 0)**2); currentInputState.accelerometer.magnitude = magnitude; if (!currentInputState.accelerometer.available) { console.log("Accelerometer data received."); currentInputState.accelerometer.available = true; currentInputState.accelerometer.history = new Array(ACCEL_FFT_SIZE).fill(magnitude); } const accelHistory = currentInputState.accelerometer.history; accelHistory.shift(); accelHistory.push(magnitude); } };
        }

        function updateCurrentGenreRuleVector() {
            const spectrumVal = menuSettings.psySpectrumPosition * 100;
            let baseLightGenre1Name, baseLightGenre2Name, interpLight;
            let baseDarkGenre1Name, baseDarkGenre2Name, interpDark;

            if (spectrumVal <= 33.33) { baseLightGenre1Name = "PSY_CHILL"; baseLightGenre2Name = "PSY_DUB"; interpLight = spectrumVal / 33.33; baseDarkGenre1Name = "DARK_PSY_CHILL"; baseDarkGenre2Name = "DARK_PSY_DUB"; interpDark = interpLight; }
            else if (spectrumVal <= 66.66) { baseLightGenre1Name = "PSY_DUB"; baseLightGenre2Name = "PSY_PROGRESSIVE"; interpLight = (spectrumVal - 33.33) / 33.33; baseDarkGenre1Name = "DARK_PSY_DUB"; baseDarkGenre2Name = "DARK_PSY_PROG"; interpDark = interpLight; }
            else { baseLightGenre1Name = "PSY_PROGRESSIVE"; baseLightGenre2Name = "PSY_FULLON"; interpLight = (spectrumVal - 66.66) / 33.34; baseDarkGenre1Name = "DARK_PSY_PROG"; baseDarkGenre2Name = "DARK_PSY"; interpDark = interpLight; }

            const baseLightGenre1 = GENRE_TARGET_STATES[baseLightGenre1Name]; const baseLightGenre2 = GENRE_TARGET_STATES[baseLightGenre2Name];
            const baseDarkGenre1 = GENRE_TARGET_STATES[baseDarkGenre1Name]; const baseDarkGenre2 = GENRE_TARGET_STATES[baseDarkGenre2Name];

            const lightContinuumVector = new Array(STATE_VECTOR_SIZE); const darkContinuumVector = new Array(STATE_VECTOR_SIZE);
            for (let i = 0; i < STATE_VECTOR_SIZE; i++) { lightContinuumVector[i] = lerp(baseLightGenre1[i], baseLightGenre2[i], interpLight); darkContinuumVector[i] = lerp(baseDarkGenre1[i], baseDarkGenre2[i], interpDark); }
            currentGenreRuleVector = new Array(STATE_VECTOR_SIZE);
            for (let i = 0; i < STATE_VECTOR_SIZE; i++) { currentGenreRuleVector[i] = lerp(lightContinuumVector[i], darkContinuumVector[i], menuSettings.darknessModifier); }
        }

        function handleSpeechCommand(command) { if (!menuSettings.enableSpeechCommands) return; console.log("Executing Speech Command:", command); let success = false; switch (command) { case 'CREATE': if (artifactManager && currentResonantState && !currentResonantState.isDisposed) { artifactManager.createArtifact(currentResonantState).then(created => { if (created) console.log("Artifact creation triggered by voice."); else console.warn("Voice artifact creation failed."); }).catch(e => console.error("Error creating artifact via voice:", e)); } else { console.warn("Cannot create artifact via voice now (system not ready?)."); } break; case 'FORGET_OLDEST': success = artifactManager?.forgetOldestArtifact() ?? false; if (success) console.log("Forget oldest artifact triggered by voice."); else console.log("Forget command failed (no artifacts?)."); break; case 'RESET': document.getElementById('resetButton').click(); break; default: console.warn("Unknown speech command received by handler:", command); } }
        function triggerVisualFeedback(intensity = 0.5, duration = 0.1) { visualFeedback.intensity = Math.max(visualFeedback.intensity, clamp(intensity, 0, 1)); visualFeedback.startTime = performance.now() / 1000.0; visualFeedback.duration = duration; visualFeedback.active = true; }
        function projectArtifactsToExternalSignal(activeArtifactInfo, targetDim) { return tf.tidy(() => { if (!activeArtifactInfo || activeArtifactInfo.stateArrays.length === 0) { return tf.keep(tf.zeros([1, 1, targetDim])); } let sumVector = new Array(STATE_VECTOR_SIZE).fill(0); let totalSimilarityWeight = 0; const numToConsider = Math.min(activeArtifactInfo.stateArrays.length, MAX_ACTIVE_ARTIFACTS_LOGIC); for (let i = 0; i < numToConsider; i++) { const stateArr = activeArtifactInfo.stateArrays[i]; const similarity = activeArtifactInfo.similarities[i]; if (stateArr && stateArr.length === STATE_VECTOR_SIZE && similarity > 0.01) { for (let j = 0; j < STATE_VECTOR_SIZE; j++) { sumVector[j] += stateArr[j] * similarity; } totalSimilarityWeight += similarity; } } if (totalSimilarityWeight > 1e-6) { for (let j = 0; j < STATE_VECTOR_SIZE; j++) { sumVector[j] /= totalSimilarityWeight; } } else { if (sumVector.length !== targetDim) { const zeroTargetDim = new Array(targetDim).fill(0.0); return tf.keep(tf.tensor1d(zeroTargetDim).reshape([1,1,targetDim])); } return tf.keep(tf.tensor1d(sumVector).reshape([1,1,targetDim])); } let projectedTensor = tf.tensor1d(sumVector); if (STATE_VECTOR_SIZE > targetDim) { projectedTensor = projectedTensor.slice([0], [targetDim]); } else if (STATE_VECTOR_SIZE < targetDim) { const padding = targetDim - STATE_VECTOR_SIZE; projectedTensor = projectedTensor.pad([[0, padding]], 0.5); } return tf.keep(projectedTensor.reshape([1, 1, targetDim])); }); }
        function processMicFFTtoStateVector(micFFT, outputDim) { return tf.tidy(() => { if (!micFFT || micFFT.length === 0) { return tf.keep(tf.zeros([1, 1, outputDim])); } const fftLength = micFFT.length; const segmentSize = Math.max(1, Math.floor(fftLength / outputDim)); const processed = new Array(outputDim).fill(0.0); for (let i = 0; i < outputDim; i++) { let sumDb = 0; let count = 0; const startBin = i * segmentSize; const endBin = Math.min((i + 1) * segmentSize, fftLength); if (startBin >= fftLength) break; for (let j = startBin; j < endBin; j++) { if (isFinite(micFFT[j]) && micFFT[j] > -120) { sumDb += (micFFT[j] + 120) / 120; count++; } } processed[i] = count > 0 ? clamp(sumDb / count, 0, 1) : 0.0; } const smoothed = new Array(outputDim); for (let i = 0; i < outputDim; i++) { const prev = processed[(i - 1 + outputDim) % outputDim] || 0; const next = processed[(i + 1) % outputDim] || 0; smoothed[i] = clamp(processed[i] * 0.6 + prev * 0.2 + next * 0.2, 0, 1); } return tf.keep(tf.tensor1d(smoothed).reshape([1,1,outputDim])); }); }

        let lastTimestamp = 0; let currentStateArray = null;
        let musicConsonanceFactor = 0.5; let lastL0Anomaly = 0.0;

        async function gameLoop(timestamp) {
             requestAnimationFrame(gameLoop);
             const currentTime = timestamp / 1000.0; currentInputState.currentTime = currentTime;
             if (!interactionOccurred && !stateLoadAttempted) { return; }
             if (stateLoadAttempted && !stateLoadSucceeded && embeddingsReady) { if(performance.now() % 2000 < 20) console.log("Waiting for state load completion..."); return; }
             if (!tf.ready() || !audioController?.isInitialized || !graphicsController?.material || !renderer || !hnmSystem || !currentResonantState || currentResonantState.isDisposed || !hnmMemoryStates || !hnmLastStepOutputs) { if(performance.now() % 5000 < 20) console.warn("Waiting for core components (TF/Audio/Graphics/HNM/Tensors)..."); return; }
             if (renderer.getContext().isContextLost()) { if(performance.now() % 5000 < 20) console.error("WebGL Context Lost! Loop paused."); return; }
             await tf.ready();
             const deltaTime = Math.max(0.001, Math.min(0.1, (timestamp - lastTimestamp) / 1000.0 || (1.0 / TARGET_FPS)));
             lastTimestamp = timestamp;

             frameCount++; const fpsElapsed = (timestamp - lastFpsTime) / 1000.0;
             if (fpsElapsed >= 1.0) { currentFPS = frameCount / fpsElapsed; lastFpsTime = timestamp; frameCount = 0; const error = TARGET_FPS - currentFPS; const baseAdjustment = 0.025; const errorFactor = Math.tanh(error / (TARGET_FPS * 0.2)) * 1.5; const adjustment = clamp(errorFactor * baseAdjustment, -0.10, 0.10); complexityLevel = clamp(complexityLevel + adjustment, 0.05, 1.0); }

             if (currentInputState.accelerometer.available && (currentTime - lastAccelTime >= ACCEL_ANALYSIS_INTERVAL_S)) { lastAccelTime = currentTime; const analysisFreq = 1.0 / ACCEL_ANALYSIS_INTERVAL_S; const accelRhythm = analyzeRhythm(currentInputState.accelerometer.history, analysisFreq, ACCEL_FFT_SIZE); currentInputState.accelerometer.rhythmPeak = accelRhythm.peak; currentInputState.accelerometer.rhythmTempo = accelRhythm.tempo; }
             currentInputState.mic = audioController?.getMicrophoneInput() ?? currentInputState.mic;
             let potentialSync = 0; if (currentInputState.mic.available && currentInputState.accelerometer.available) { const micPeakNorm = currentInputState.mic.rhythmPeak; const accelPeakNorm = currentInputState.accelerometer.rhythmPeak; const tempoDiff = Math.abs(currentInputState.mic.rhythmTempo - currentInputState.accelerometer.rhythmTempo); const tempoSimilarity = Math.max(0, 1.0 - tempoDiff / 80.0); potentialSync = micPeakNorm * accelPeakNorm * tempoSimilarity * 2.0; }
             currentInputState.syncFactor = clamp(currentInputState.syncFactor * SYNC_DECAY + potentialSync * (1.0 - SYNC_DECAY), 0.0, 1.0);

            let differenceVectorTensor; let tempPrevMusicStateForDiff; let tempMicSensedMusicForDiff;
            if (currentResonantState && !currentResonantState.isDisposed) { tempPrevMusicStateForDiff = tf.keep(currentResonantState.clone()); } else { tempPrevMusicStateForDiff = tf.keep(tf.fill([1, 1, STATE_VECTOR_SIZE], 0.5)); }
            if (currentInputState.mic.available && currentInputState.mic.fft) { tempMicSensedMusicForDiff = processMicFFTtoStateVector(currentInputState.mic.fft, STATE_VECTOR_SIZE); } else { tempMicSensedMusicForDiff = tf.keep(tf.zeros([1, 1, STATE_VECTOR_SIZE])); }
            try { differenceVectorTensor = tf.tidy(() => tf.keep(tempPrevMusicStateForDiff.sub(tempMicSensedMusicForDiff).abs())); const sim = tf.tidy(() => tf.scalar(1.0).sub(tf.losses.cosineDistance(tempPrevMusicStateForDiff.squeeze(), tempMicSensedMusicForDiff.squeeze(), 0))); musicConsonanceFactor = clamp(sim.dataSync()[0], -1.0, 1.0); sim.dispose(); }
            catch (e) { console.warn("Error calculating difference vector or consonance:", e); if (differenceVectorTensor && !differenceVectorTensor.isDisposed) differenceVectorTensor.dispose(); differenceVectorTensor = tf.keep(tf.zeros([1, 1, STATE_VECTOR_SIZE])); musicConsonanceFactor = 0.0; }
            if (tempPrevMusicStateForDiff && !tempPrevMusicStateForDiff.isDisposed) tempPrevMusicStateForDiff.dispose();
            if (tempMicSensedMusicForDiff && !tempMicSensedMusicForDiff.isDisposed) tempMicSensedMusicForDiff.dispose();

             const nowMs = Date.now();
             if (embeddingsReady && artifactManager && (nowMs - lastArtifactCreationTime > ARTIFACT_CREATION_INTERVAL_MS)) {
                 lastArtifactCreationTime = nowMs;
                 try {
                    let tempPrevMusicStateForStdDev; if (currentResonantState && !currentResonantState.isDisposed) { tempPrevMusicStateForStdDev = currentResonantState.clone(); } else { tempPrevMusicStateForStdDev = tf.fill([1, 1, STATE_VECTOR_SIZE], 0.5); }
                    const prevStateDataForStdDev = await tempPrevMusicStateForStdDev.squeeze([0,1]).data(); tempPrevMusicStateForStdDev.dispose();
                     const mean = prevStateDataForStdDev.reduce((a, b) => a + b, 0) / prevStateDataForStdDev.length; const variance = prevStateDataForStdDev.reduce((a, b) => a + (b - mean) ** 2, 0) / prevStateDataForStdDev.length; const botOutputStabilityMetric = 1.0 - Math.sqrt(variance);
                     const l0AnomalyContribution = clamp(lastL0Anomaly * 2.5, 0.0, 1.0);
                     const activityLevel = (l0AnomalyContribution*0.60 + currentInputState.mic.rhythmPeak*0.15 + currentInputState.accelerometer.rhythmPeak*0.10 + (1.0-botOutputStabilityMetric)*0.15);
                     const syncBoost = 1.0 + (currentInputState.syncFactor - 0.5) * 0.5; const minThresh = ARTIFACT_CREATION_ACTIVITY_THRESHOLD_MIN * syncBoost; const maxThresh = ARTIFACT_CREATION_ACTIVITY_THRESHOLD_MAX * syncBoost;
                     if (activityLevel > minThresh && activityLevel < maxThresh && artifactManager.getArtifactCount() < MAX_ARTIFACTS) { console.log(`Attempting artifact creation: Activity=${activityLevel.toFixed(3)} (L0AnomCont: ${l0AnomalyContribution.toFixed(2)}), Sync=${currentInputState.syncFactor.toFixed(2)} (Thresh: ${minThresh.toFixed(2)}-${maxThresh.toFixed(2)})`); window._hnmShouldCreateArtifactThisFrame = true; }
                     else { if (artifactManager.getArtifactCount() >= MAX_ARTIFACTS) { if(performance.now() % 10000 < 20) console.log(`Artifact creation skipped: Max artifacts reached (${MAX_ARTIFACTS}).`); } else { if(performance.now() % 10000 < 20) console.log(`Artifact creation skipped: Activity=${activityLevel.toFixed(3)} (L0AnomCont: ${l0AnomalyContribution.toFixed(2)}) (Thresh: ${minThresh.toFixed(2)}-${maxThresh.toFixed(2)})`); } window._hnmShouldCreateArtifactThisFrame = false; }
                 } catch (dataError) { console.error("Error during artifact creation pre-check:", dataError); window._hnmShouldCreateArtifactThisFrame = false; }
             } else { window._hnmShouldCreateArtifactThisFrame = false; }

              if (artifactManager && currentResonantState && !currentResonantState.isDisposed) { activeArtifactInfo = await artifactManager.findRelevantArtifacts(currentResonantState, ARTIFACT_SIMILARITY_THRESHOLD, MAX_ACTIVE_ARTIFACTS_LOGIC).catch(e => { console.error("Error finding relevant artifacts:", e); return { ids: [], stateArrays: [], similarities: [] }; }); } else { activeArtifactInfo = { ids: [], stateArrays: [], similarities: [] }; }
             memoryInfo = tf.memory();
            let previousMusicStateTensorForHNMInput; if (currentResonantState && !currentResonantState.isDisposed) { previousMusicStateTensorForHNMInput = tf.keep(currentResonantState.clone()); } else { previousMusicStateTensorForHNMInput = tf.keep(tf.fill([1, 1, STATE_VECTOR_SIZE], 0.5)); }

             try {
                 const hnmStepPackage = tf.tidy("HNM_Step_Execution", () => {
                     const playerIntentUnscaled = inputProcessorModel.process(currentInputState, currentTime); const playerIntentScaled = playerIntentUnscaled.mul(tf.scalar(menuSettings.playerInfluence));
                     let l0SensoryInput = previousMusicStateTensorForHNMInput.add(playerIntentScaled).clipByValue(0, 1);
                     const l0Name = HNM_HIERARCHY_LEVEL_CONFIGS[0].name; const sensoryInputsForHNM = { [l0Name]: l0SensoryInput };
                     const externalInputsAllSources = {}; const artifactSignalTensor = projectArtifactsToExternalSignal(activeArtifactInfo, HNM_ARTIFACT_EXTERNAL_SIGNAL_DIM);
                     let diffVecScaled; if (differenceVectorTensor && !differenceVectorTensor.isDisposed) { diffVecScaled = differenceVectorTensor.mul(tf.scalar(menuSettings.micFeedbackToL0Strength || 0.0)); } else { diffVecScaled = tf.zeros([1,1,HNM_ARTIFACT_EXTERNAL_SIGNAL_DIM]); console.warn("Difference vector was invalid for HNM L0 external input, using zeros."); }
                     let combinedL0External = diffVecScaled.add(artifactSignalTensor).clipByValue(0,1); externalInputsAllSources["ArtifactSignalSource"] = combinedL0External;
                     let genreRuleTensorFullForHNMStep; if (currentGenreRuleVector && currentGenreRuleVector.length === STATE_VECTOR_SIZE) { genreRuleTensorFullForHNMStep = tf.tensor1d(currentGenreRuleVector).reshape([1, 1, HNM_GENRE_RULE_EXTERNAL_SIGNAL_DIM]); } else { genreRuleTensorFullForHNMStep = tf.zeros([1, 1, HNM_GENRE_RULE_EXTERNAL_SIGNAL_DIM]); }
                     // Note: For L1, the genre rule influence is scaled by genreRuleInfluence, but this happens *after* the HNM step for direct output blending.
                     // For the HNM step itself, if we were to use "add_to_target" with learning, we might send a differently scaled one.
                     // Here, we send the full rule vector for "add_to_target" in HNM, but the learning rate is 0.
                     // The *effective* genre influence on output is handled post-HNM step.
                     externalInputsAllSources["ActiveGenreRuleSignal"] = genreRuleTensorFullForHNMStep.clone(); // HNM gets the rule, but its effect on output is overridden later
                     
                     const hnsStepResults = hnmSystem.step(hnmMemoryStates, hnmLastStepOutputs, sensoryInputsForHNM, externalInputsAllSources, true);
                     
                     let hnmL1Output = tf.keep(hnsStepResults.newlyRetrievedValues[HNM_POLICY_HEAD_INPUT_LEVEL_NAME].clone());
                     let finalBlendedOutput;
                     
                     // Direct blending for Genre Rule Influence
                     const genreInfluence = menuSettings.genreRuleInfluence;
                     const tempGenreRuleTensorScaled = genreRuleTensorFullForHNMStep.mul(tf.scalar(genreInfluence));
                     finalBlendedOutput = hnmL1Output.mul(tf.scalar(1.0 - genreInfluence)).add(tempGenreRuleTensorScaled);
                     finalBlendedOutput = finalBlendedOutput.clipByValue(0,1);
                     tf.dispose(hnmL1Output); // Dispose the original L1 output
                     hnmL1Output = tf.keep(finalBlendedOutput); // Keep the blended one

                     if (menuSettings.explorationInfluence > 0.001) { 
                        let totalAnomaly = 0; 
                        for (const levelName_anom in hnsStepResults.anomalies) { 
                            if (hnsStepResults.anomalies[levelName_anom] && !hnsStepResults.anomalies[levelName_anom].isDisposed) { 
                                totalAnomaly += hnsStepResults.anomalies[levelName_anom].dataSync()[0]; 
                                if (levelName_anom === l0Name) { lastL0Anomaly = hnsStepResults.anomalies[levelName_anom].dataSync()[0]; } 
                            } 
                        } 
                        const perturbationFactor = clamp(totalAnomaly * menuSettings.explorationInfluence * 0.05, 0, 0.1); 
                        if (perturbationFactor > 1e-5) { 
                            const perturbation = tf.randomNormal(hnmL1Output.shape).mul(tf.scalar(perturbationFactor)); 
                            const perturbedState = hnmL1Output.add(perturbation).clipByValue(0,1); 
                            hnmL1Output.dispose(); 
                            hnmL1Output = tf.keep(perturbedState); 
                            perturbation.dispose(); 
                        } 
                     } else { 
                        if (hnsStepResults.anomalies[l0Name] && !hnsStepResults.anomalies[l0Name].isDisposed) { 
                            lastL0Anomaly = hnsStepResults.anomalies[l0Name].dataSync()[0]; 
                        } else { lastL0Anomaly = 0.0; } 
                     }
                     playerIntentUnscaled.dispose(); playerIntentScaled.dispose(); artifactSignalTensor.dispose(); diffVecScaled.dispose(); genreRuleTensorFullForHNMStep.dispose(); tempGenreRuleTensorScaled.dispose();
                     return { newResonantState: hnmL1Output, nextHnmStates: hnsStepResults.nextBotStates, nextHnmOutputs: hnsStepResults.newlyRetrievedValues, hnsAnomaliesEtc: { anomalies: tf.keep(hnsStepResults.anomalies), weightChanges: tf.keep(hnsStepResults.weightChanges), buNorms: tf.keep(hnsStepResults.buNorms), tdNorms: tf.keep(hnsStepResults.tdNorms), extNorms: tf.keep(hnsStepResults.extNorms) } };
                 });
                 if (previousMusicStateTensorForHNMInput && !previousMusicStateTensorForHNMInput.isDisposed) { previousMusicStateTensorForHNMInput.dispose(); }
                 if (differenceVectorTensor && !differenceVectorTensor.isDisposed) { differenceVectorTensor.dispose(); }
                 tf.dispose(currentResonantState); hnmMemoryStates.forEach(levelState => window.disposeMemStateWeights(levelState)); Object.values(hnmLastStepOutputs).forEach(out_obj => { if (out_obj && out_obj.retrievedVal && !out_obj.retrievedVal.isDisposed) { out_obj.retrievedVal.dispose(); } });
                 currentResonantState = hnmStepPackage.newResonantState; hnmMemoryStates = hnmStepPackage.nextHnmStates; hnmLastStepOutputs = hnmStepPackage.nextHnmOutputs;
                 window.disposeHnsResultsTensors(hnmStepPackage.hnsAnomaliesEtc); memoryInfo = tf.memory();
             } catch (e) {
                 console.error("!!! Game Loop TF/HNM Error:", e); memoryInfo = tf.memory();
                 if (previousMusicStateTensorForHNMInput && !previousMusicStateTensorForHNMInput.isDisposed) previousMusicStateTensorForHNMInput.dispose();
                 if (currentResonantState && !currentResonantState.isDisposed) currentResonantState.dispose(); currentResonantState = tf.keep(tf.fill([1, 1, STATE_VECTOR_SIZE], 0.5)); lastL0Anomaly = 0.0;
                 if (differenceVectorTensor && !differenceVectorTensor.isDisposed) differenceVectorTensor.dispose();
                 if (hnmSystem) { if (hnmMemoryStates) hnmMemoryStates.forEach(levelState => window.disposeMemStateWeights(levelState)); hnmMemoryStates = hnmSystem.getInitialStates(); if (hnmLastStepOutputs) Object.values(hnmLastStepOutputs).forEach(out_obj => { if(out_obj && out_obj.retrievedVal && !out_obj.retrievedVal.isDisposed) out_obj.retrievedVal.dispose(); }); hnmLastStepOutputs = {}; hnmSystem.levelConfigsOriginal.forEach(levelConfig => { hnmLastStepOutputs[levelConfig.name] = { retrievedVal: tf.keep(tf.zeros([1, 1, levelConfig.dim])) }; if (levelConfig.name === HNM_POLICY_HEAD_INPUT_LEVEL_NAME && currentResonantState && !currentResonantState.isDisposed) { if (hnmLastStepOutputs[levelConfig.name].retrievedVal && !hnmLastStepOutputs[levelConfig.name].retrievedVal.isDisposed) { hnmLastStepOutputs[levelConfig.name].retrievedVal.dispose(); } hnmLastStepOutputs[levelConfig.name].retrievedVal = tf.keep(currentResonantState.clone()); } }); }
             }

            if (window._hnmShouldCreateArtifactThisFrame === true) { if (artifactManager && currentResonantState && !currentResonantState.isDisposed) { artifactManager.createArtifact(currentResonantState).then(created => { if (created && currentInputState.syncFactor > SYNC_THRESHOLD) { console.log("Artifact created (post-HNM) during high ambient sync!"); triggerVisualFeedback(0.9, 0.35); } else if (created) { console.log("Artifact created (post-HNM, low/no sync)."); triggerVisualFeedback(0.6, 0.2); } }).catch(e => console.error("Error during post-HNM artifact creation:", e)); } window._hnmShouldCreateArtifactThisFrame = false; }
              if (currentResonantState && !currentResonantState.isDisposed) { try { currentStateArray = await currentResonantState.squeeze([0,1]).dataSync(); } catch (dataError) { console.error("Error getting state tensor data after HNM step:", dataError); currentStateArray = currentStateArray || new Array(STATE_VECTOR_SIZE).fill(0.5); } } else { currentStateArray = currentStateArray || new Array(STATE_VECTOR_SIZE).fill(0.5); console.warn("Using fallback/previous state array post-HNM."); }
             let currentFeedbackIntensity = 0; if (visualFeedback.active) { const elapsed = currentTime - visualFeedback.startTime; if (elapsed < visualFeedback.duration) { const progress = elapsed / visualFeedback.duration; currentFeedbackIntensity = visualFeedback.intensity * (1.0 - progress) * (1.0 - progress); } else { visualFeedback.active = false; visualFeedback.intensity = 0; } }
             const shaderArtifactInfo = { ids: activeArtifactInfo.ids.slice(0, MAX_ARTIFACTS_SHADER), stateArrays: activeArtifactInfo.stateArrays.slice(0, MAX_ARTIFACTS_SHADER), similarities: activeArtifactInfo.similarities.slice(0, MAX_ARTIFACTS_SHADER) };
             if (currentStateArray) { graphicsController?.update(currentStateArray, currentTime, shaderArtifactInfo, complexityLevel, currentInputState.syncFactor, currentFeedbackIntensity); }
             if (currentResonantState && !currentResonantState.isDisposed) { audioController?.update(currentResonantState, complexityLevel, menuSettings); }

             if (USE_DEBUG && document.getElementById('debugInfo')) { const d = document.getElementById('debugInfo'); const { numBytes, numTensors } = memoryInfo || { numBytes: 0, numTensors: 0 }; const artCnt = artifactManager?.getArtifactCount() ?? 0; const logicArtIds = activeArtifactInfo.ids.join(',') || 'n'; const shArtIds = shaderArtifactInfo.ids.join(',') || 'n'; const mtn = currentInputState.motion.available ? `${currentInputState.motion.beta.toFixed(0)},${currentInputState.motion.gamma.toFixed(0)}`:'N'; const mic = currentInputState.mic.available ? `${currentInputState.mic.level.toFixed(2)}[${currentInputState.mic.rhythmPeak.toFixed(1)},${currentInputState.mic.rhythmTempo.toFixed(0)}]`:'N'; const acc = currentInputState.accelerometer.available ? `${currentInputState.accelerometer.magnitude.toFixed(1)}[${currentInputState.accelerometer.rhythmPeak.toFixed(1)},${currentInputState.accelerometer.rhythmTempo.toFixed(0)}]`:'N'; const be = tf.getBackend()||'N'; const speechStat = speechController ? speechController.updateStatus() : 'N/A'; const menuDbg = `BPM:${menuSettings.masterBPM.toFixed(0)} PI:${(menuSettings.playerInfluence*100).toFixed(0)} GI:${(menuSettings.genreRuleInfluence*100).toFixed(0)} Exp:${(menuSettings.explorationInfluence*100).toFixed(0)}`; d.textContent = `V${VERSION.split('-')[0]}|FPS:${currentFPS.toFixed(1)}|L0Anom:${lastL0Anomaly.toFixed(3)}|Cons:${musicConsonanceFactor.toFixed(2)}|Sync:${currentInputState.syncFactor.toFixed(2)}|${menuDbg}|Ctx:${audioContext?.state??'N'}|Tch:${currentInputState.touch.active?'A':'I'}|Mtn:${mtn}|Acc:${acc}|Mic:${mic}|Speech:${speechStat}|Art:${artCnt}(L:${logicArtIds}/${MAX_ACTIVE_ARTIFACTS_LOGIC}|S:${shArtIds}/${MAX_ARTIFACTS_SHADER})|Emb:${embeddingsReady?'OK':'No'}|TF[${be}]:${numTensors}t/${(numBytes/1e6).toFixed(1)}MB`; }
        }

        function saveStateToLocalStorage() { if (!interactionOccurred || !currentResonantState || currentResonantState.isDisposed || !artifactManager || !embeddingsReady) { if (performance.now() % 15000 < 20) console.log("Save HNM/RAG state skipped (conditions not met)."); return; } console.log("Saving HNM/RAG state to localStorage..."); try { currentResonantState.squeeze([0,1]).data().then(stateArray => { const serializableArts = artifactManager.artifacts.map(art => ({ id: art.id, stateVector: Array.from(art.stateVector), featureTags: art.featureTags, embedding: Array.from(art.embedding), timestamp: art.timestamp })); const stateToSave = { resonantState: Array.from(stateArray), artifacts: serializableArts, timestamp: Date.now(), version: VERSION }; const stateJSON = JSON.stringify(stateToSave); localStorage.setItem(LOCAL_STORAGE_KEY, stateJSON); console.log(`HNM/RAG State (${(stateJSON.length / 1024).toFixed(1)} KB) saved.`); }).catch(e => { console.error("Error getting tensor data for saving HNM/RAG state:", e); showWarning("Failed to get data for HNM/RAG save.", 3000); }); } catch (e) { console.error("Save HNM/RAG state error:", e); if (e.name === 'QuotaExceededError') { showError("Save HNM/RAG Failed: Storage full!"); if(artifactManager?.getArtifactCount() > 0) { console.warn("Attempting prune oldest artifact due to QuotaExceededError..."); artifactManager.forgetOldestArtifact(); } } else { showWarning("Could not save HNM/RAG state.", 3000); } } }
        function loadStateFromLocalStorage() { stateLoadAttempted = true; stateLoadSucceeded = false; let stateJSON; try { stateJSON = localStorage.getItem(LOCAL_STORAGE_KEY); if (!stateJSON) { console.log(`No saved HNM/RAG state found for key '${LOCAL_STORAGE_KEY}'.`); stateLoadSucceeded = true; return false; } console.log(`Loading HNM/RAG state for key '${LOCAL_STORAGE_KEY}'...`); const savedState = JSON.parse(stateJSON); if (!savedState || typeof savedState !== 'object') throw new Error("Invalid saved HNM/RAG state format (not an object)."); if (savedState.version !== VERSION) { console.warn(`Saved HNM/RAG state version mismatch (Need v${VERSION}, got v${savedState.version}). Clearing.`); throw new Error("HNM/RAG Version mismatch."); } if (!Array.isArray(savedState.resonantState) || savedState.resonantState.length !== STATE_VECTOR_SIZE) throw new Error("Invalid resonantState format or size."); if (!Array.isArray(savedState.artifacts)) throw new Error("Invalid artifacts format."); tf.tidy(() => { const validatedStateArray = savedState.resonantState.map(v => typeof v === 'number' && isFinite(v) ? clamp(v, 0, 1) : 0.5); const loadedTensor = tf.tensor1d(validatedStateArray).reshape([1, 1, STATE_VECTOR_SIZE]); tf.dispose(currentResonantState); currentResonantState = loadedTensor; }); tf.keep(currentResonantState); console.log("Restored HNM output state (currentResonantState). HNM internal memory will reinitialize."); if (hnmSystem) { if (hnmMemoryStates) hnmMemoryStates.forEach(levelState => window.disposeMemStateWeights(levelState)); hnmMemoryStates = hnmSystem.getInitialStates(); if (hnmLastStepOutputs) Object.values(hnmLastStepOutputs).forEach(out_obj => { if(out_obj && out_obj.retrievedVal && !out_obj.retrievedVal.isDisposed) out_obj.retrievedVal.dispose(); }); hnmLastStepOutputs = {}; hnmSystem.levelConfigsOriginal.forEach(levelConfig => { hnmLastStepOutputs[levelConfig.name] = { retrievedVal: tf.keep(tf.zeros([1, 1, levelConfig.dim])) }; if (levelConfig.name === HNM_POLICY_HEAD_INPUT_LEVEL_NAME && currentResonantState && !currentResonantState.isDisposed) { if (hnmLastStepOutputs[levelConfig.name].retrievedVal && !hnmLastStepOutputs[levelConfig.name].retrievedVal.isDisposed) { hnmLastStepOutputs[levelConfig.name].retrievedVal.dispose(); } hnmLastStepOutputs[levelConfig.name].retrievedVal = tf.keep(currentResonantState.clone()); } }); } const artifactsToLoad = savedState.artifacts; let loadCheckRetries = 0; const MAX_LOAD_RETRIES = 50; const checkAndSetArtifacts = () => { if (artifactManager && embeddingsReady) { artifactManager.setArtifacts(artifactsToLoad); showWarning("Loaded previous HNM/RAG state.", 3000); console.log(`Artifacts loaded from save point: ${new Date(savedState.timestamp).toLocaleString()}`); stateLoadSucceeded = true; } else if (loadCheckRetries < MAX_LOAD_RETRIES) { loadCheckRetries++; setTimeout(checkAndSetArtifacts, 200); } else { console.error("Timeout waiting for artifact manager/embeddings during HNM/RAG state load. Artifacts not loaded."); showError("Load Failed: Components timeout. Artifacts lost."); stateLoadSucceeded = true; } }; setTimeout(checkAndSetArtifacts, 100); interactionOccurred = true; return true; } catch (e) { console.error("Load HNM/RAG state error:", e); showError("Failed to load HNM/RAG state. Starting fresh."); if (e instanceof SyntaxError) { console.error("-> Likely corrupted JSON in localStorage for HNM/RAG state:", stateJSON?.substring(0, 100)); } try { localStorage.removeItem(LOCAL_STORAGE_KEY); } catch (removeError) { console.error("Error removing corrupted HNM/RAG state:", removeError); } stateLoadSucceeded = true; return false; } }

        function saveMenuSettingsToLocalStorage() {
            try { const settingsToSave = {}; for(const key in defaultMenuSettings){ if(menuSettings.hasOwnProperty(key)) settingsToSave[key] = menuSettings[key];} settingsToSave.version = VERSION; localStorage.setItem(LOCAL_STORAGE_MENU_KEY, JSON.stringify(settingsToSave)); console.log("Menu settings saved with current version: " + VERSION); } catch (e) { console.error("Error saving menu settings to localStorage:", e); }
        }
        function loadMenuSettingsFromLocalStorage() {
            const hnmRagResetJustOccurred = sessionStorage.getItem('hnm_rag_reset_just_occurred') === 'true'; if (hnmRagResetJustOccurred) { sessionStorage.removeItem('hnm_rag_reset_just_occurred'); console.log("HNM/RAG reset detected. Attempting to preserve menu settings."); }
            let settingsLoadedAndApplied = false;
            try { const savedSettingsJSON = localStorage.getItem(LOCAL_STORAGE_MENU_KEY); if (savedSettingsJSON) { const savedSettings = JSON.parse(savedSettingsJSON); const applyLoadedSettings = (sourceSettings) => { for(const key in defaultMenuSettings){ if(sourceSettings.hasOwnProperty(key) && typeof sourceSettings[key] === typeof defaultMenuSettings[key]){ menuSettings[key] = sourceSettings[key]; } else { menuSettings[key] = defaultMenuSettings[key]; } } }; if (hnmRagResetJustOccurred) { console.log(`HNM/RAG Reset: Loading menu settings (saved version ${savedSettings.version || 'unknown'}). Current app version ${VERSION}.`); applyLoadedSettings(savedSettings); console.log("Menu settings (potentially from old version) applied after HNM/RAG reset. Re-saving with current app version."); saveMenuSettingsToLocalStorage(); settingsLoadedAndApplied = true; } else { if (savedSettings.version === VERSION) { applyLoadedSettings(savedSettings); console.log("Menu settings loaded from localStorage (version match)."); settingsLoadedAndApplied = true; } else { console.warn(`Menu settings version mismatch (Need v${VERSION}, got v${savedSettings.version || 'unknown'}). Applying defaults and resaving.`); } } } else { console.log("No saved menu settings found in localStorage."); }
            } catch (e) { console.error("Error loading/parsing menu settings from localStorage:", e.message); }
            if (!settingsLoadedAndApplied) { console.log("Applying default menu settings and saving."); resetMenuSettingsToDefault(false); saveMenuSettingsToLocalStorage(); } 
            if (gui) { gui.controllersRecursive().forEach(controller => { if (menuSettings.hasOwnProperty(controller.property)) { controller.setValue(menuSettings[controller.property]); } }); }
            updateCurrentGenreRuleVector();
        }
        function resetMenuSettingsToDefault(save = true) {
            for(const key in defaultMenuSettings){ if(menuSettings.hasOwnProperty(key)) menuSettings[key] = defaultMenuSettings[key]; }
            if (gui) { gui.controllersRecursive().forEach(controller => { if (menuSettings.hasOwnProperty(controller.property)) { controller.setValue(menuSettings[controller.property]); } }); }
            updateCurrentGenreRuleVector(); if(save) saveMenuSettingsToLocalStorage(); console.log("Menu settings reset to default" + (save ? " and saved." : "."));
        }

        const genreEditControllers = [];
        function loadSelectedGenreToSliders() {
            const selectedGenreName = menuSettings.genreEdit_Selected;
            if (GENRE_TARGET_STATES[selectedGenreName]) {
                const genreState = GENRE_TARGET_STATES[selectedGenreName];
                menuSettings._genreEdit_tempState = [...genreState]; 
                for (let i = 0; i < GENRE_EDIT_SLIDER_COUNT; i++) {
                    const stateVectorIndex = GENRE_EDIT_SLIDER_MAPPING[i];
                    menuSettings[`genreEdit_Param${i}`] = genreState[stateVectorIndex];
                }
                genreEditControllers.forEach(c => c.updateDisplay());
                showWarning(`Loaded '${selectedGenreName}' to genre editor.`, 2000);
            } else { showError(`Genre '${selectedGenreName}' not found for editing.`); }
        }
        function saveSlidersToSelectedGenre() {
            const selectedGenreName = menuSettings.genreEdit_Selected;
            if (GENRE_TARGET_STATES[selectedGenreName]) {
                const targetGenreArray = GENRE_TARGET_STATES[selectedGenreName];
                for (let i = 0; i < GENRE_EDIT_SLIDER_COUNT; i++) {
                    const stateVectorIndex = GENRE_EDIT_SLIDER_MAPPING[i];
                    targetGenreArray[stateVectorIndex] = menuSettings[`genreEdit_Param${i}`];
                }
                for(let i = 0; i < STATE_VECTOR_SIZE; i++) {
                    if (!GENRE_EDIT_SLIDER_MAPPING.includes(i) && menuSettings._genreEdit_tempState[i] !== undefined) {
                        targetGenreArray[i] = menuSettings._genreEdit_tempState[i];
                    }
                }
                updateCurrentGenreRuleVector(); 
                showWarning(`Saved sliders to '${selectedGenreName}' (in memory for this session). Menu settings saved.`, 4000);
            } else { showError(`Genre '${selectedGenreName}' not found for saving.`); }
        }

        async function initialize() {
            console.log(`Initializing Infundibulum Echoes v${VERSION}`);
            const warningDiv = document.getElementById('warningInfo');
            if (USE_DEBUG) document.getElementById('debugInfo').style.display = 'block';

            gui = new GUI({ autoPlace: true, title: `Echoes Controls v${VERSION.split('-')[0]}` });

            const systemFolder = gui.addFolder('System & State');
            systemFolder.add(menuSettings, 'enableSpeechCommands').name('Enable Speech').onChange((value) => { console.log("Speech Commands " + (value ? "Enabled" : "Disabled")); if (!value) { speechController?.stopListening(); } else { if (speechController && speechController.permissionGranted && !speechController.isListening && !speechController.isActive && !speechController.isStarting) { speechController.startListening(); } } saveMenuSettingsToLocalStorage(); });
            systemFolder.add(menuSettings, 'enableTapReset').name('Enable Tap Reset').onChange((value) => { console.log("Tap Reset Gesture " + (value ? "Enabled" : "Disabled")); saveMenuSettingsToLocalStorage(); });
            systemFolder.add(menuSettings, 'resetMenuToDefaults').name('Reset Menu Defaults');
            systemFolder.add(menuSettings, 'resetHnmRag').name('Reset HNM/RAG State');

            const hnmInfluenceFolder = gui.addFolder('HNM & Player Influence');
            hnmInfluenceFolder.add(menuSettings, 'playerInfluence', 0, 1, 0.01).name('Player Influence').onChange(saveMenuSettingsToLocalStorage);
            hnmInfluenceFolder.add(menuSettings, 'genreRuleInfluence', 0, 1, 0.01).name('Genre Rule Influence').onChange(saveMenuSettingsToLocalStorage);
            hnmInfluenceFolder.add(menuSettings, 'micFeedbackToL0Strength', 0, 1, 0.01).name('MicDiff Ext.Strength(L0)').onChange(saveMenuSettingsToLocalStorage);
            hnmInfluenceFolder.add(menuSettings, 'explorationInfluence', 0, 1, 0.01).name('HNM Anomaly Explor.').onChange(saveMenuSettingsToLocalStorage);

            const genreSelectFolder = gui.addFolder('Genre Selection');
            genreSelectFolder.add(menuSettings, 'psySpectrumPosition', 0, 1, 0.01).name('Psy Spectrum').onChange(() => { updateCurrentGenreRuleVector(); saveMenuSettingsToLocalStorage(); });
            genreSelectFolder.add(menuSettings, 'darknessModifier', 0, 1, 0.01).name('Darkness Modifier').onChange(() => { updateCurrentGenreRuleVector(); saveMenuSettingsToLocalStorage(); });
            genreSelectFolder.add(menuSettings, 'masterBPM', 60, 220, 1).name('Master BPM').onChange(saveMenuSettingsToLocalStorage);

            const kickFolder = gui.addFolder('Kick Drum');
            kickFolder.add(menuSettings, 'kickTune', 0, 1, 0.01).name('Tune (Low-High)').onChange(saveMenuSettingsToLocalStorage);
            kickFolder.add(menuSettings, 'kickPunch', 0, 1, 0.01).name('Punch/Body').onChange(saveMenuSettingsToLocalStorage);
            kickFolder.add(menuSettings, 'kickDecay', 0.01, 1, 0.01).name('Amp Decay').onChange(saveMenuSettingsToLocalStorage);
            kickFolder.add(menuSettings, 'kickClick', 0, 1, 0.01).name('Click Level').onChange(saveMenuSettingsToLocalStorage);
            kickFolder.add(menuSettings, 'kickLevel', 0, 1, 0.01).name('Level').onChange(saveMenuSettingsToLocalStorage);

            const bassFolder = gui.addFolder('Bass');
            bassFolder.add(menuSettings, 'bassOscType', { Saw: 0, Square: 1} ).name('Osc Type').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassOctave', 0, 1, 0.01).name('Octave (Low-Mid)').onChange(saveMenuSettingsToLocalStorage); 
            bassFolder.add(menuSettings, 'bassCutoff', 0.01, 1, 0.01).name('Filter Cutoff').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassReso', 0, 1, 0.01).name('Filter Reso').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassEnvAmt', 0, 1, 0.01).name('Filter Env Amt').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassFilterDecay', 0.01, 0.5, 0.005).name('Filter Decay').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassAmpDecay', 0.01, 0.5, 0.005).name('Amp Decay').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassFilterLfoRate', 0, 1, 0.01).name('Filt LFO Rate').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassFilterLfoDepth', 0, 1, 0.01).name('Filt LFO Depth').onChange(saveMenuSettingsToLocalStorage);
            bassFolder.add(menuSettings, 'bassLevel', 0, 1, 0.01).name('Level').onChange(saveMenuSettingsToLocalStorage);

            const leadFolder = gui.addFolder('Lead Synth');
            leadFolder.add(menuSettings, 'leadOscType', { Saw:0, Square:1, FMish:2 } ).name('Osc Type').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadOctave', 0, 1, 0.01).name('Octave (Mid-High)').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadPW', 0.05, 0.95, 0.01).name('Pulse Width').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadCutoff', 0.01, 1, 0.01).name('Filter Cutoff').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadReso', 0, 1, 0.01).name('Filter Reso').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadEnvAmt', 0, 1, 0.01).name('Filter Env Amt').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadFilterDecay', 0.01, 1, 0.01).name('Filter Decay').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadAmpDecay', 0.01, 2, 0.01).name('Amp Decay').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadPitchLfoRate', 0, 1, 0.01).name('Pitch LFO Rate').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadPitchLfoDepth', 0, 1, 0.01).name('Pitch LFO Depth').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadFilterLfoRate', 0, 1, 0.01).name('Filt LFO Rate').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadFilterLfoDepth', 0, 1, 0.01).name('Filt LFO Depth').onChange(saveMenuSettingsToLocalStorage);
            leadFolder.add(menuSettings, 'leadLevel', 0, 1, 0.01).name('Level').onChange(saveMenuSettingsToLocalStorage);

            const hatsFolder = gui.addFolder('Hi-Hats');
            hatsFolder.add(menuSettings, 'hatClosedDecay', 0.005, 0.2, 0.001).name('Closed Decay').onChange(saveMenuSettingsToLocalStorage);
            hatsFolder.add(menuSettings, 'hatOpenDecay', 0.05, 0.5, 0.005).name('Open Decay').onChange(saveMenuSettingsToLocalStorage);
            hatsFolder.add(menuSettings, 'hatHpfCutoff', 0.1, 1, 0.01).name('HPF Cutoff').onChange(saveMenuSettingsToLocalStorage);
            hatsFolder.add(menuSettings, 'hatTone', 0, 1, 0.01).name('Tone Adjust').onChange(saveMenuSettingsToLocalStorage);
            hatsFolder.add(menuSettings, 'hatLevel', 0, 1, 0.01).name('Level').onChange(saveMenuSettingsToLocalStorage);

            const snareFolder = gui.addFolder('Snare');
            snareFolder.add(menuSettings, 'snareNoiseLevel', 0, 1, 0.01).name('Noise Level').onChange(saveMenuSettingsToLocalStorage);
            snareFolder.add(menuSettings, 'snareNoiseDecay', 0.01, 0.3, 0.005).name('Noise Decay').onChange(saveMenuSettingsToLocalStorage);
            snareFolder.add(menuSettings, 'snareBodyTune', 0, 1, 0.01).name('Body Tune').onChange(saveMenuSettingsToLocalStorage);
            snareFolder.add(menuSettings, 'snareBodyDecay', 0.01, 0.5, 0.005).name('Body Decay').onChange(saveMenuSettingsToLocalStorage);
            snareFolder.add(menuSettings, 'snareBodyLevel', 0, 1, 0.01).name('Body Level').onChange(saveMenuSettingsToLocalStorage);
            snareFolder.add(menuSettings, 'snareLevel', 0, 1, 0.01).name('Master Level').onChange(saveMenuSettingsToLocalStorage);

            const noiseFxFolder = gui.addFolder('Noise FX');
            noiseFxFolder.add(menuSettings, 'noiseFxFiltType', { LP:0, HP:1, BP:2 }).name('Filter Type').onChange(saveMenuSettingsToLocalStorage);
            noiseFxFolder.add(menuSettings, 'noiseFxCutoff', 0.01, 1, 0.01).name('Cutoff').onChange(saveMenuSettingsToLocalStorage);
            noiseFxFolder.add(menuSettings, 'noiseFxReso', 0, 1, 0.01).name('Resonance').onChange(saveMenuSettingsToLocalStorage);
            noiseFxFolder.add(menuSettings, 'noiseFxLfoRate', 0, 1, 0.01).name('LFO Rate').onChange(saveMenuSettingsToLocalStorage);
            noiseFxFolder.add(menuSettings, 'noiseFxLfoDepth', 0, 1, 0.01).name('LFO Depth').onChange(saveMenuSettingsToLocalStorage);
            noiseFxFolder.add(menuSettings, 'noiseFxLevel', 0, 1, 0.005).name('Level').onChange(saveMenuSettingsToLocalStorage);

            const delayFxFolder = gui.addFolder('Delay FX');
            delayFxFolder.add(menuSettings, 'delayTimeMode', { "1/16":0, "1/8":1, "3/16":2, "1/4":3, "1/2":4 }).name('Time Mode').onChange(saveMenuSettingsToLocalStorage);
            delayFxFolder.add(menuSettings, 'delayFeedback', 0, 0.98, 0.01).name('Feedback').onChange(saveMenuSettingsToLocalStorage);
            delayFxFolder.add(menuSettings, 'delayMix', 0, 1, 0.01).name('Mix').onChange(saveMenuSettingsToLocalStorage);

            const reverbFxFolder = gui.addFolder('Reverb FX');
            reverbFxFolder.add(menuSettings, 'reverbSize', 0.1, 1, 0.01).name('Size/Decay').onChange(saveMenuSettingsToLocalStorage);
            reverbFxFolder.add(menuSettings, 'reverbDamp', 0, 1, 0.01).name('Damping').onChange(saveMenuSettingsToLocalStorage);
            reverbFxFolder.add(menuSettings, 'reverbMix', 0, 1, 0.01).name('Mix').onChange(saveMenuSettingsToLocalStorage);

            const genreEditFolder = gui.addFolder('Genre Editor (HNM Targets)');
            genreEditFolder.add(menuSettings, 'genreEdit_Selected', Object.keys(GENRE_TARGET_STATES)).name('Edit Genre').onChange(loadSelectedGenreToSliders);
            genreEditFolder.add(menuSettings, 'genreEdit_LoadToSliders').name('Load to Sliders');
            for(let i = 0; i < GENRE_EDIT_SLIDER_COUNT; i++) {
                const controller = genreEditFolder.add(menuSettings, `genreEdit_Param${i}`, 0, 1, 0.01).name(`P${GENRE_EDIT_SLIDER_MAPPING[i]}`);
                genreEditControllers.push(controller);
            }
            genreEditFolder.add(menuSettings, 'genreEdit_SaveToSelected').name('Save Sliders to Genre');

            try { graphicsController = new GraphicsController(document.getElementById('renderCanvas')); } catch(e) { showError("Fatal: Graphics Controller Init Failed. Check console."); console.error("Graphics Controller critical initialization failure:", e); return; }
            audioController = new AudioController();

            try { await tf.ready(); const targetBackend = 'webgl'; let currentBackend = tf.getBackend(); if (currentBackend !== targetBackend) { console.log(`Attempting to set TF backend to ${targetBackend}...`); await tf.setBackend(targetBackend).catch(async (be) => { console.warn(`Failed setting preferred backend ${targetBackend}, current: ${tf.getBackend()}. Error:`, be); }); } currentBackend = tf.getBackend(); console.log(`TF Ready. Backend: ${currentBackend}`); if (currentBackend === 'webgl') { tf.env().set('WEBGL_CONV_IM2COL', false); tf.env().set('WEBGL_PACK', false); tf.env().set('WEBGL_USE_SHAPES_UNIFORMS', true); tf.env().set('WEBGL_FORCE_F16_TEXTURES', true); } else { console.warn(`Running on non-WebGL TF Backend: ${currentBackend}. Performance may vary.`); } console.log("TF backend configured. TF Memory (Initial):", tf.memory());
            } catch (err) { showError("Fatal: TF.js Backend Init Failed. Check console."); console.error("TensorFlow.js setup critical failure:", err); return; }

            if (HNM_HIERARCHY_LEVEL_CONFIGS[0].name === "L0_IntentProcessing") { HNM_HIERARCHY_LEVEL_CONFIGS[0].raw_sensory_input_dim = STATE_VECTOR_SIZE; console.log(`Set L0_IntentProcessing.raw_sensory_input_dim to STATE_VECTOR_SIZE (${STATE_VECTOR_SIZE})`); } else { console.error("Could not find L0_IntentProcessing to set its raw_sensory_input_dim."); showError("Fatal: HNM Config error for L0 input. Check console."); return; }
            if (INPUT_VECTOR_SIZE !== STATE_VECTOR_SIZE) { console.error(`CRITICAL: INPUT_VECTOR_SIZE (${INPUT_VECTOR_SIZE}) must match STATE_VECTOR_SIZE (${STATE_VECTOR_SIZE}).`); showError("Fatal: Vector Size Mismatch. Check console."); return; }

            inputProcessorModel = new PlaceholderInputProcessor(INPUT_VECTOR_SIZE, STATE_VECTOR_SIZE);
            if (typeof window.HierarchicalSystemV5_TFJS === 'undefined') { showError("Fatal: HNM Core Script not loaded. Check console."); return; }
            const hnmGlobalSimConfig = { HNM_VERBOSE: HNM_VERBOSE };
            hnmSystem = new window.HierarchicalSystemV5_TFJS(HNM_HIERARCHY_LEVEL_CONFIGS, hnmGlobalSimConfig);
            hnmMemoryStates = hnmSystem.getInitialStates(); hnmLastStepOutputs = {};
            hnmSystem.levelConfigsOriginal.forEach(levelConfig => { hnmLastStepOutputs[levelConfig.name] = { retrievedVal: tf.keep(tf.zeros([1, 1, levelConfig.dim])) }; });

            featureExtractor = new FeatureExtractor(STATE_VECTOR_SIZE); embeddingProvider = new EmbeddingProvider(EMBEDDING_MODEL_NAME);
            artifactManager = new ArtifactManager(MAX_ARTIFACTS, STATE_VECTOR_SIZE, EMBEDDING_DIM, featureExtractor, embeddingProvider);
            speechController = new SpeechRecognitionController(); speechController.setCommandCallback(handleSpeechCommand);
            console.log("Logic/RAG/Speech/HNM components instantiated.");

            loadMenuSettingsFromLocalStorage(); 
            loadSelectedGenreToSliders(); 

            const hnmLoadSuccess = loadStateFromLocalStorage();
            if (!hnmLoadSuccess && !stateLoadSucceeded) { console.log("Initialized with default HNM/RAG state (no valid save found or load failed)."); warningDiv.textContent = `Ready (v${VERSION.split('-')[0]}). Interact or Speak. Long Press + Tap to Reset.`; stateLoadSucceeded = true; }
            else if (hnmLoadSuccess) { console.log("HNM/RAG state load initiated, waiting for completion..."); warningDiv.textContent = `Loading State (v${VERSION.split('-')[0]})...`; }
            else { warningDiv.textContent = `Ready (v${VERSION.split('-')[0]}). Interact or Speak. Long Press + Tap to Reset.`; }

            embeddingProvider.init().catch(e => console.error("Background Embedding Model init error:", e));
            setupInputListeners();
            window.addEventListener('resize', () => { graphicsController?.resize(); }, { passive: true });
            document.addEventListener('visibilitychange', () => { if (document.hidden) { saveStateToLocalStorage(); speechController?.stopListening(); } else { audioController?.tryInitializeAudio(); if(menuSettings.enableSpeechCommands && speechController?.permissionGranted && !speechController.isListening && !speechController.isActive) { speechController.startListening(); } } });
            window.addEventListener('pagehide', () => { saveStateToLocalStorage(); saveMenuSettingsToLocalStorage(); });
            if (!renderer) { showError("Initialization Error: Renderer became invalid."); return; }
            console.log("Initialization complete. Starting game loop (will wait for interaction or state load)...");
            lastTimestamp = performance.now(); lastFpsTime = lastTimestamp; lastAccelTime = lastTimestamp / 1000.0;
            requestAnimationFrame(gameLoop);
        }

        function showError(msg) { const w=document.getElementById('warningInfo'); if(w){ w.textContent=`FATAL: ${msg}`; w.style.color='red'; w.style.display='block'; if(audioController?.warningTimeout) clearTimeout(audioController.warningTimeout); if (audioController) audioController.audioWarningDisplayed = true; } console.error(`FATAL: ${msg}`); }
        function showWarning(msg, dur=5000) { audioController?.showWarning(msg, dur); }
        function hideWarning() { audioController?.hideWarning(); }
        function showLoading(show, msg="") { const l=document.getElementById('loadingInfo'); const p=document.getElementById('loadingProgress'); if(l){ l.style.display=show?'flex':'none'; l.style.flexDirection='column'; l.style.alignItems='center'; l.style.justifyContent='center'; if(show && p){ l.childNodes[0].nodeValue = msg + '\n'; p.textContent=''; } } }
        function clamp(v,min,max){return Math.max(min,Math.min(v,max));}
        function fract(n){return n-Math.floor(n);}
        function lerp(a, b, t) { return a * (1 - t) + b * t; }

        if (typeof tf !== 'undefined' && typeof THREE !== 'undefined') { setTimeout(initialize, 150); }
        else { showError("Fatal: Core libraries (TF/Three) failed load."); console.error("TF.js or Three.js was not found. Check network connection and script tags."); const d = document.getElementById('loadingInfo'); if (d) { d.innerHTML = "ERROR: Core library failed.<br>Refresh/check console."; d.style.display = 'flex'; d.style.color = 'red'; } }
    </script>
</body>
</html>

